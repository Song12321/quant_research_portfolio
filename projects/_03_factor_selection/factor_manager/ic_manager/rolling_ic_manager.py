"""
æ»šåŠ¨ICç®¡ç†å™¨ - è§£å†³å‰è§†åå·®çš„å…³é”®ç»„ä»¶

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ—¶ç‚¹åŒ–ICè®¡ç®—ï¼šä¸¥æ ¼æŒ‰æ—¶é—´ç‚¹æ»šåŠ¨è®¡ç®—ICï¼Œé¿å…æœªæ¥ä¿¡æ¯æ³„éœ²
2. å¢é‡å­˜å‚¨ï¼šæ”¯æŒå¢é‡è®¡ç®—å’Œå­˜å‚¨ï¼Œæå‡æ•ˆç‡
3. çª—å£ç®¡ç†ï¼šçµæ´»çš„å›çœ‹çª—å£é…ç½®
4. æ•°æ®å®Œæ•´æ€§ï¼šç¡®ä¿ICè®¡ç®—çš„æ—¶é—´ä¸€è‡´æ€§

è®¾è®¡ç†å¿µï¼š
- å®Œå…¨æœç»å‰è§†åå·®
- æ”¯æŒå®ç›˜çº§åˆ«çš„ä¸¥æ ¼æ—¶é—´æ§åˆ¶
- é«˜æ•ˆçš„å¢é‡è®¡ç®—å’Œå­˜å‚¨
"""
import math
from scipy import stats

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import json

from projects._03_factor_selection.factor_manager.storage.result_load_manager import ResultLoadManager
from projects._03_factor_selection.config_manager.config_snapshot.config_snapshot_manager import ConfigSnapshotManager
from projects._03_factor_selection.utils.date.trade_date_utils import get_end_day_pre_n_day
from quant_lib.config.logger_config import setup_logger
from quant_lib.evaluation.evaluation import _calculate_newey_west_tstat

logger = setup_logger(__name__)


@dataclass
class ICCalculationConfig:
    """ICè®¡ç®—é…ç½®"""
    lookback_months: int = 12  # å›çœ‹çª—å£(æœˆ) ç›®å‰å†™æ­»-æ³¨æ„è°ƒæ•´ 0.1
    forward_periods: List[str] = None  # å‰å‘æ”¶ç›Šå‘¨æœŸ
    min_require_observations: int = 120  # æœ€å°è§‚æµ‹æ•°é‡  ç›®å‰å†™æ­»-æ³¨æ„è°ƒæ•´ 0.1
    calculation_frequency: str = 'M'  # è®¡ç®—é¢‘ç‡ ('M'=æœˆæœ«, 'Q'=å­£æœ«)
    significance_threshold: float = 1.96  # æ˜¾è‘—æ€§é˜ˆå€¼ (95%ç½®ä¿¡åº¦)
    ewma_span: int = 126  # EWMAçª—å£ (çº¦åŠå¹´)
    max_monthly_turnover: float = 0.40  # æœ€å¤§æœˆåº¦æ¢æ‰‹ç‡ä¸Šé™
    turnover_mode: str = 'calculate'  # æ¢æ‰‹ç‡è®¡ç®—æ¨¡å¼: 'estimate'(ç»éªŒä¼°ç®—) æˆ– 'calculate'(åŠ¨æ€è®¡ç®—)

    def __init__(self,lookback_months=12, forward_periods: list=None , min_require_observations: int = 120, calculation_frequency: str = 'M',calcu_type='o2o', version='20190328_20231231', turnover_mode='estimate'):
        self.lookback_months = lookback_months
        self.forward_periods = forward_periods
        self.min_require_observations = min_require_observations
        self.calculation_frequency = calculation_frequency
        self.turnover_mode = turnover_mode

        self.calcu_type=calcu_type
        self.version=version


@dataclass
class ICSnapshot:
    """ICå¿«ç…§æ•°æ®ç»“æ„"""
    calculation_date: str  # è®¡ç®—æ—¶ç‚¹
    factor_name: str  # å› å­åç§°
    stock_pool_index: str  # è‚¡ç¥¨æ± 
    window_start: str  # å›çœ‹çª—å£èµ·ç‚¹
    window_end: str  # å›çœ‹çª—å£ç»ˆç‚¹
    ic_stats: Dict[str, Dict]  # å„å‘¨æœŸICç»Ÿè®¡
    metadata: Dict  # å…ƒæ•°æ®ä¿¡æ¯


class RollingICManager:
    """æ»šåŠ¨ICç®¡ç†å™¨ - æ— å‰è§†åå·®çš„ICè®¡ç®—ä¸å­˜å‚¨"""

    def __init__(self,calcu_return_type, config: Optional[ICCalculationConfig] = None,version=None):
        self.main_work_path = Path(
            r"D:\lqs\codeAbout\py\Quantitative\import_file\quant_research_portfolio\workspace\result")
        self.config = config or ICCalculationConfig()
        self.calcu_return_type=calcu_return_type
        self.version = version

        # æ—¶ç‚¹ICç´¢å¼•
        self._ic_index = {}
        self._load_ic_index()
    #ok è‚‰çœ¼é€è¡Œdebug æ•°æ®å®Œç¾
    def calculate_and_store_rolling_ic(
            self,
            factor_names: List[str],
            stock_pool_index: str,
            start_date: str,
            end_date: str,
            resultLoadManager:ResultLoadManager,  # æ•°æ®æº
            force_recalculate: bool = False
    ) -> Dict[str, List[ICSnapshot]]:
        """
        è®¡ç®—å¹¶å­˜å‚¨æ»šåŠ¨IC
        
        Args:
            factor_names: å› å­åç§°åˆ—è¡¨
            stock_pool_index: è‚¡ç¥¨æ± åç§°
            start_date: å¼€å§‹è®¡ç®—æ—¶ç‚¹
            end_date: ç»“æŸè®¡ç®—æ—¶ç‚¹
            factor_data_source: å› å­æ•°æ®æº
            return_data_source: æ”¶ç›Šæ•°æ®æº
            force_recalculate: æ˜¯å¦å¼ºåˆ¶é‡æ–°è®¡ç®—
            
        Returns:
            Dict[factor_name, List[ICSnapshot]]: æ‰€æœ‰å› å­çš„ICå¿«ç…§åºåˆ—
        """
        logger.info(f"ğŸ”„ å¼€å§‹æ»šåŠ¨ICè®¡ç®—: {start_date} -> {end_date}")
        logger.info(f"ğŸ“Š å› å­æ•°é‡: {len(factor_names)}, è‚¡ç¥¨æ± : {stock_pool_index}")

        # 1. ç”Ÿæˆè®¡ç®—æ—¶ç‚¹åºåˆ—
        calculation_dates = self._generate_calculation_dates(start_date, end_date)
        logger.info(f"â° è®¡ç®—æ—¶ç‚¹æ•°é‡: {len(calculation_dates)}")

        # 2. é€æ—¶ç‚¹è®¡ç®—IC
        all_factor_snapshots = {name: [] for name in factor_names}

        for calc_date in calculation_dates:
            logger.info(f"ğŸ“… è®¡ç®—æ—¶ç‚¹: {calc_date}")

            for factor_name in factor_names:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è®¡ç®—ç»“æœ
                    if not force_recalculate and self._snapshot_exists(
                            factor_name, stock_pool_index, calc_date
                    ):
                        snapshot = self._load_snapshot(factor_name, stock_pool_index, calc_date)
                        logger.debug(f"  ğŸ“¥ {factor_name}: ä½¿ç”¨å·²æœ‰å¿«ç…§")
                    else:
                        # è®¡ç®—æ–°çš„ICå¿«ç…§
                        snapshot = self._calculate_ic_snapshot(
                            factor_name, stock_pool_index, calc_date,
                            resultLoadManager
                        )

                        if snapshot:
                            self._save_snapshot(snapshot)
                            # logger.debug(f"  âœ… {factor_name}:{calc_date} ICå¿«ç…§è®¡ç®—å®Œæˆ")
                        else:#å¾ˆæ­£å¸¸å•Šï¼Œæ¯”å¦‚ä¸æ»¡è¶³è§‚æµ‹ç‚¹ä¸ªæ•°çš„æ—¶å€™
                            continue

                    all_factor_snapshots[factor_name].append(snapshot)

                except Exception as e:
                    logger.error(f"  âŒ {factor_name}: ICè®¡ç®—å¼‚å¸¸ - {e}")
                    continue

        logger.info(f"âœ… æ»šåŠ¨ICè®¡ç®—å®Œæˆ")
        return all_factor_snapshots

    def get_ic_at_timepoint(
            self,
            factor_name: str,
            stock_pool: str,
            calculation_date: str
    ) -> Optional[ICSnapshot]:
        """è·å–æŒ‡å®šæ—¶ç‚¹çš„ICå¿«ç…§"""
        return self._load_snapshot(factor_name, stock_pool, calculation_date)

    def get_ic_series(
            self,
            factor_name: str,
            stock_pool: str,
            start_date: str,
            end_date: str
    ) -> List[ICSnapshot]:
        """è·å–æ—¶é—´åºåˆ—çš„ICå¿«ç…§"""
        snapshots = []

        # ä»ç´¢å¼•ä¸­æŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„å¿«ç…§
        key_pattern = f"{factor_name}_{stock_pool}"

        for key, metadata in self._ic_index.items():
            if key.startswith(key_pattern):
                calc_date = metadata['calculation_date']
                if start_date <= calc_date <= end_date:
                    snapshot = self._load_snapshot(factor_name, stock_pool, calc_date)
                    if snapshot:
                        snapshots.append(snapshot)

        # æŒ‰è®¡ç®—æ—¶ç‚¹æ’åº
        snapshots.sort(key=lambda x: x.calculation_date)
        return snapshots

    def _calculate_ic_snapshot(
            self,
            factor_name: str,
            stock_pool_index: str,
            calculation_date: str,#æœˆåº¦å¿«ç…§ 1231 0131 0229 0331.ã€‚
            resultLoadManager:ResultLoadManager
    ) -> Optional[ICSnapshot]:
        """è®¡ç®—å•ä¸ªæ—¶ç‚¹çš„ICå¿«ç…§"""
        try:
            # 1. ç¡®å®šå›çœ‹çª—å£ï¼ˆä¸¥æ ¼é¿å…å‰è§†åå·®ï¼‰
            calc_date = pd.Timestamp(calculation_date)
            window_end = calc_date #todo åº”è¯¥æ˜¯ä»¥æ®period cal_date å‡å» period
            window_start = calc_date - relativedelta(months=self.config.lookback_months) #å›çœ‹12ä¸ªæœˆ

            # 2. è·å–çª—å£å†…çš„å› å­æ•°æ®
            factor_data = resultLoadManager.get_factor_data(
                factor_name, stock_pool_index,
                window_start.strftime('%Y-%m-%d'),
                window_end.strftime('%Y-%m-%d')
            )

            if factor_data is None or factor_data.empty:
                raise ValueError(f"å› å­ {factor_name} åœ¨çª—å£ {window_start}-{window_end} å†…æ— æ•°æ®")

            # 3. è®¡ç®—å„å‘¨æœŸICç»Ÿè®¡
            ic_stats = {}

            for period in self.config.forward_periods:
                # è·å–å‰å‘æ”¶ç›Šæ•°æ®
                period_days = period
                return_end = window_end + timedelta(days=period_days + 10)  # ç•™å……è¶³ä½™é‡

                return_data = resultLoadManager.get_o2o_return_data(
                    stock_pool_index,
                    window_start.strftime('%Y-%m-%d'),
                    return_end.strftime('%Y-%m-%d'),
                    period_days
                )

                if return_data is None or return_data.empty:
                    raise ValueError('æ”¶ç›Šç‡æ•°æ®ä¸å¯èƒ½ä¸ºç©ºï¼ï¼Œä¸¥é‡é”™è¯¯ï¼')

                # æ ¹æ®é¢„æµ‹å‘¨æœŸï¼Œç¡®å®šå› å­æ•°æ®çš„æœ‰æ•ˆæˆªæ­¢æ—¥æœŸ
                # ç«™åœ¨ calc_dateï¼Œè¦è¯„ä»·ä¸€ä¸ªé¢„æµ‹æœŸä¸º period çš„å› å­ï¼Œ
                # æœ€æ™šçš„å› å­æ—¥æœŸ T å¿…é¡»æ»¡è¶³ T + period <= calc_dateã€‚
                # c. å¯¹åŸå§‹çš„ã€å®Œæ•´çš„å› å­æ•°æ®è¿›è¡Œã€æˆªæ–­ã€‘ï¼Œå¾—åˆ°æœ¬æ¬¡è®¡ç®—æ‰€éœ€çš„å®‰å…¨å­é›†
                # 1. ç²¾ç¡®è®¡ç®—å‡ºå› å­æ•°æ®åœ¨æ­¤å‘¨æœŸä¸‹çš„æœ‰æ•ˆæˆªæ­¢æ—¥æœŸ
                effective_end_date = get_end_day_pre_n_day(calculation_date,period)
                # 2. ä½¿ç”¨å¸ƒå°”ç´¢å¼•ï¼ŒåŸºäºã€æ—¥æœŸã€‘è¿›è¡Œè¿‡æ»¤
                factor_data = factor_data[factor_data.index <= effective_end_date]


                # è®¡ç®—IC
                period_ic_stats = self.generate_ic_snapshot_stats(
                    factor_data, return_data, period_days,
                    factor_name=factor_name,
                    stock_pool_index=stock_pool_index,
                    resultLoadManager=resultLoadManager
                )

                if period_ic_stats:
                    ic_stats[period] = period_ic_stats

            if not ic_stats:
                logger.warning(f"å› å­ {factor_name} åœ¨æ—¶ç‚¹ {calculation_date} æ— æœ‰æ•ˆICç»Ÿè®¡--æ­£å¸¸ï¼šå› ä¸ºä¸æ»¡è¶³120ä¸ªè§‚æµ‹ç‚¹ï¼ï¼ˆäººè¯ï¼šå›å¤´çœ‹çš„å¤©æ•°æ²¡æœ‰è¾¾åˆ°120å¤©")
                return None

            # 4. æ„å»ºICå¿«ç…§
            snapshot = ICSnapshot(
                calculation_date=calculation_date,
                factor_name=factor_name,
                stock_pool_index=stock_pool_index,
                window_start=window_start.strftime('%Y-%m-%d'),
                window_end=window_end.strftime('%Y-%m-%d'),
                ic_stats=ic_stats,
                metadata={
                    'config_manager': {
                        'lookback_months': self.config.lookback_months,
                        'min_require_observations': self.config.min_require_observations
                    },
                    'data_points': len(factor_data),
                    'created_timestamp': datetime.now().isoformat()
                }
            )

            return snapshot

        except Exception as e:
            logger.error(f"è®¡ç®—ICå¿«ç…§å¤±è´¥ {factor_name}@{calculation_date}: {e}")
            return None

    def generate_ic_snapshot_stats(
        self,
        factor_data: pd.DataFrame,
        return_data: pd.DataFrame,
        period_days: int,
        factor_name: str = None,
        stock_pool_index: str = None,
        resultLoadManager = None
    ) -> Optional[Dict]:
        """è®¡ç®—ç‰¹å®šå‘¨æœŸçš„ICç»Ÿè®¡ - ä¿®å¤é‡å çª—å£åå·®"""
        try:
            # å¯¹é½å› å­å’Œæ”¶ç›Šæ•°æ®
            aligned_factor, aligned_return = self._align_data(factor_data, return_data)

            if len(aligned_factor) < self.config.min_require_observations:
                return None
            ic_series= resultLoadManager.get_ic_series_by_period(stock_pool_index, factor_name, period_days)
            if len(ic_series) == 0:
                logger.info(f"å› å­ {factor_name} éé‡å é‡‡æ ·åæ— æœ‰æ•ˆICç»Ÿè®¡ icä¸ªæ•°ä¸º0")
                return None

            # ICç»Ÿè®¡æŒ‡æ ‡ - ä½¿ç”¨EWMAåŠ¨æ€è®¡ç®— (å¯é…ç½®spanï¼Œé»˜è®¤126çº¦ç­‰äºåŠå¹´)
            ewma_span = getattr(self.config, 'ewma_span', 126)

            # æ³¨æ„ï¼šç”±äºéé‡å é‡‡æ ·åæ ·æœ¬æ•°å‡å°‘ï¼Œéœ€è¦è°ƒæ•´EWMAå‚æ•°
            adjusted_ewma_span = min(ewma_span // period_days, len(ic_series) // 2)#æœˆåº¦ï¼šç»“æœ6
            if adjusted_ewma_span < 6:
                # æ ·æœ¬å¤ªå°‘ï¼Œä½¿ç”¨ä¼ ç»Ÿç»Ÿè®¡æ–¹æ³•
                ic_mean = ic_series.mean()
                ic_std_ewma = ic_series.std()
                ic_std_rolling = ic_series.std()
            else:
                ic_mean = ic_series.ewm(span=adjusted_ewma_span).mean().iloc[-1]
                ic_std_ewma = ic_series.ewm(span=adjusted_ewma_span).std().iloc[-1]
                ic_std_rolling = ic_series.std()

            ic_ir = ic_mean / ic_std_ewma if ic_std_ewma > 0 else 0
            # ç¡®å®šé•¿æœŸæ–¹å‘ï¼Œå¢åŠ é˜ˆå€¼ä¿æŠ¤
            threshold_mean = 0.001
            long_term_ic_mean = ic_series.mean()
            if abs(long_term_ic_mean) < threshold_mean:
                # æ–¹å‘ä¸æ˜æ˜¾ï¼Œç›´æ¥æŒ‰æ­£å‘å¤„ç†æˆ–ç•¥è¿‡
                factor_direction = 1
            else:
                factor_direction = np.sign(long_term_ic_mean)

            # èƒœè´Ÿåºåˆ—ï¼ˆä¿ç•™æ–¹å‘æ€§ï¼‰
            win_loss_series = ((ic_series * factor_direction) > 0).astype(int)#åŒå·

            # EWMA èƒœç‡
            ic_win_rate_ewma = win_loss_series.ewm(span=ewma_span).mean().iloc[-1]
            # tæ£€éªŒ (ä¼ ç»Ÿ)
            from scipy import stats
            t_stat, p_value = stats.ttest_1samp(ic_series, 0)

            # åŠ¨æ€Newey-West T-stat (ç¨³å¥ç‰ˆå¼‚æ–¹å·®è°ƒæ•´) ä¸éœ€è¦ewmaå¤„ç† ï¼ˆå› ä¸ºä»–æœ¬è´¨æ˜¯å…¨é‡ç»Ÿè®¡
            ic_nw_t_stat, ic_nw_p_value = _calculate_newey_west_tstat(ic_series) #ok

            #åŠ¨æ€è®¡ç®— (åŸºäºå®é™…æ’åå˜åŒ–)
            avg_daily_rank_change_turnover_stats  = self._calculate_daily_rank_change(
                factor_name,aligned_factor, stock_pool_index, ic_series.index, resultLoadManager
            )
            # è®¡ç®—æ˜¾è‘—æ€§æ ‡è®°å’Œè´¨é‡è¯„ä¼°
            significance_threshold = getattr(self.config, 'significance_threshold', 1.96)
            max_turnover = getattr(self.config, 'max_monthly_turnover', 0.40)

            is_significant_nw = abs(ic_nw_t_stat) > significance_threshold
            is_significant_traditional = abs(t_stat) > significance_threshold

            # ç»¼åˆè´¨é‡è¯„çº§
            quality_score = self._calculate_quality_score(
                ic_mean, ic_ir, ic_win_rate_ewma, ic_nw_t_stat, avg_daily_rank_change_turnover_stats.get('avg_daily_rank_change', 0)
            )

            return {
                'ic_mean': float(ic_mean),
                'ic_std_ewma': float(ic_std_ewma),  # æ–°å¢EWMAæ ‡å‡†å·®
                'ic_std_rolling': float(ic_std_rolling),  # ä¿ç•™å…¨æ ·æœ¬æ ‡å‡†å·®
                'ic_ir': float(ic_ir),  # åŸºäºEWMAæ ‡å‡†å·®çš„IR
                'ic_win_rate': float(ic_win_rate_ewma) ,
                'ic_t_stat': float(t_stat),  # ä¼ ç»Ÿtç»Ÿè®¡é‡
                'ic_p_value': float(p_value),
                'ic_nw_t_stat': float(ic_nw_t_stat),  # Newey-Westè°ƒæ•´Tç»Ÿè®¡é‡
                'ic_nw_p_value': float(ic_nw_p_value),  # å¯¹åº”på€¼
                'ic_count': len(ic_series),
                'ic_max': float(ic_series.max()),
                'ic_min': float(ic_series.min()),
                # æ–°å¢è´¨é‡æŒ‡æ ‡
                'is_significant_nw': bool(is_significant_nw),  # Newey-Westæ˜¾è‘—æ€§
                'is_significant_traditional': bool(is_significant_traditional),  # ä¼ ç»Ÿæ˜¾è‘—æ€§
                'avg_daily_rank_change_stats': avg_daily_rank_change_turnover_stats,  # æ¢æ‰‹ç‡çº¦æŸ
                # 'quality_score': float(quality_score),  # ç»¼åˆè´¨é‡è¯„åˆ†
                **avg_daily_rank_change_turnover_stats  # åŠ¨æ€æ¢æ‰‹ç‡ç»Ÿè®¡
            }

        except Exception as e:
            raise  ValueError(f"è®¡ç®—å‘¨æœŸICå¤±è´¥: {e}")
    #a give


    def _calculate_quality_score(
        self, 
        ic_mean: float, 
        ic_ir: float, 
        ic_win_rate: float, 
        nw_t_stat: float, 
        avg_daily_rank_change: float
    ) -> float:
        """
        è®¡ç®—å› å­ç»¼åˆè´¨é‡è¯„åˆ† (0-1èŒƒå›´)
        
        è€ƒè™‘å› ç´ :
        1. ICç»å¯¹å€¼ (40%æƒé‡)
        2. IRæŒ‡æ ‡ (25%æƒé‡) 
        3. æ˜¾è‘—æ€§ (20%æƒé‡)
        4. èƒœç‡ (10%æƒé‡)
        5. æ¢æ‰‹ç‡æƒ©ç½š (5%æƒé‡)
        """
        try:
            # 1. ICå¼ºåº¦è¯„åˆ† (0-1)
            ic_score = min(abs(ic_mean) / 0.05, 1.0) * 0.4
            
            # 2. IRæŒ‡æ ‡è¯„åˆ† (0-1) 
            ir_score = min(abs(ic_ir) / 2.0, 1.0) * 0.25
            
            # 3. æ˜¾è‘—æ€§è¯„åˆ† (0-1)
            significance_score = min(abs(nw_t_stat) / 3.0, 1.0) * 0.2
            
            # 4. èƒœç‡è¯„åˆ† (0-1)
            win_rate_score = max(0, (ic_win_rate - 0.5) * 2) * 0.1
            
            # 5. æ¢æ‰‹ç‡æƒ©ç½š (0-1)
            turnover_penalty = max(0, 1 - avg_daily_rank_change / 0.5) * 0.05
            
            total_score = ic_score + ir_score + significance_score + win_rate_score + turnover_penalty
            return min(total_score, 1.0)
            
        except:
            return 0.0
    
    def _calculate_daily_rank_change(
        self, 
        factor_name: str,
        factor_data: pd.DataFrame,
        stock_pool_index: str,
        date_index: pd.DatetimeIndex,
        resultLoadManager = None
    ) -> Dict[str, float]:
        """
       åŸºäºå®é™…å› å­æ’åå˜åŒ–)
        
        Args:
            factor_name: å› å­åç§°
            stock_pool_index: è‚¡ç¥¨æ± ç´¢å¼•
            date_index: ICè®¡ç®—æ—¥æœŸç´¢å¼•
            resultLoadManager: æ•°æ®åŠ è½½ç®¡ç†å™¨
            è¡¡é‡äº†åœ¨æ•´ä¸ªè‚¡ç¥¨æ± ä¸­ï¼Œè‚¡ç¥¨çš„â€œåº§æ¬¡â€å¹³å‡å‘ç”Ÿäº†å¤šå¤§çš„å˜åŒ–ã€‚
        Returns:
            Dict: æ¢æ‰‹ç‡ç›¸å…³ç»Ÿè®¡æŒ‡æ ‡
        """
        try:
            if resultLoadManager is None or len(date_index) < 2:
                return self._get_empty_turnover_stats()

            if factor_data is None or factor_data.empty:
                logger.debug(f"å› å­ {factor_name} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—åŠ¨æ€æ¢æ‰‹ç‡")
                return self._get_empty_turnover_stats()
            
            # 2. è®¡ç®—æ¯ä¸ªæ—¥æœŸçš„å› å­æ’åç™¾åˆ†ä½ (ä½¿ç”¨åˆ†ä½æ•°æ’åï¼Œæ›´ç¨³å®š)
            monthly_rankings = {}
            monthly_dates = sorted(date_index)
            
            for calc_date in monthly_dates:
                calc_timestamp = pd.Timestamp(calc_date)
                
                # è·å–è¯¥æœˆæœ«å‰åå‡ å¤©çš„æ•°æ®æ¥å¢å¼ºç¨³å®šæ€§
                #é˜²æ­¢åœ¨è¿›è¡Œ1231è®¡ç®—æœˆåº¦å¿«ç…§è®¡ç®—ï¼Œå‘ç°1230 1229 éƒ½æ²¡æœ‰æ•°æ®ï¼ï¼ˆå¯èƒ½æ˜¯å‡æœŸ
                window_start = calc_timestamp - pd.Timedelta(days=5)
                window_end = calc_timestamp + pd.Timedelta(days=1)
                
                # åœ¨å› å­æ•°æ®ä¸­æ‰¾åˆ°æœ€æ¥è¿‘çš„äº¤æ˜“æ—¥
                available_dates = factor_data.index
                valid_dates = available_dates[
                    (available_dates >= window_start) & (available_dates <= window_end)
                ]
                
                if len(valid_dates) == 0:
                    continue
                
                # ä½¿ç”¨æœ€æ¥è¿‘ç›®æ ‡æ—¥æœŸçš„æ•°æ®
                target_date = valid_dates[np.argmin(np.abs((valid_dates - calc_timestamp).days))]
                daily_factor = factor_data.loc[target_date].dropna()
                
                if len(daily_factor) < 10:  # è‡³å°‘éœ€è¦10åªè‚¡ç¥¨
                    continue
                
                # è®¡ç®—åˆ†ä½æ•°æ’å (0-1ä¹‹é—´)
                rankings = daily_factor.rank(pct=True, method='average')
                monthly_rankings[calc_date] = rankings
            
            if len(monthly_rankings) < 2:
                logger.debug(f"å› å­ {factor_name} æœ‰æ•ˆæ’åæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ¢æ‰‹ç‡")
                return self._get_empty_turnover_stats()
            
            # 3. è®¡ç®—ç›¸é‚»æœŸé—´çš„æ’åå˜åŒ– (æ¢æ‰‹ç‡è®¡ç®—)
            turnover_rates = []
            ranking_dates = sorted(monthly_rankings.keys())
            
            for i in range(1, len(ranking_dates)):
                prev_date = ranking_dates[i-1]
                curr_date = ranking_dates[i]
                
                prev_rankings = monthly_rankings[prev_date]
                curr_rankings = monthly_rankings[curr_date]
                
                # æ‰¾åˆ°ä¸¤æœŸå…±åŒçš„è‚¡ç¥¨
                common_stocks = prev_rankings.index.intersection(curr_rankings.index)
                
                if len(common_stocks) < 10:
                    continue
                
                prev_common = prev_rankings.loc[common_stocks]
                curr_common = curr_rankings.loc[common_stocks]
                
                # è®¡ç®—æ’åå˜åŒ–çš„ç»å¯¹å€¼å¹³å‡ (è¿™æ˜¯æ¢æ‰‹ç‡çš„æ ¸å¿ƒæŒ‡æ ‡)
                ranking_changes = np.abs(curr_common - prev_common)
                mean_absolute_rank_change = ranking_changes.mean()
                
                turnover_rates.append(mean_absolute_rank_change)
            
            if len(turnover_rates) == 0:
                return self._get_empty_turnover_stats()
            
            # 4. ç»Ÿè®¡æ¢æ‰‹ç‡æ—¶é—´åºåˆ—
            turnover_array = np.array(turnover_rates)
            
            avg_daily_rank_change = np.mean(turnover_array)
            daily_turnover_volatility = float(np.std(turnover_array))
            
            # è®¡ç®—æ¢æ‰‹ç‡è¶‹åŠ¿ (çº¿æ€§å›å½’æ–œç‡)
            if len(turnover_rates) >= 3:
                x = np.arange(len(turnover_rates))
                z = np.polyfit(x, turnover_array, 1)
                daily_turnover_trend = z[0]    #æ–œç‡
            else:
                daily_turnover_trend = 0.0
            
            return {
                'avg_daily_rank_change': float(avg_daily_rank_change),
                'daily_turnover_volatility': float(daily_turnover_volatility),
                'daily_turnover_trend': float(daily_turnover_trend),
                'sample_periods': len(turnover_rates),
                'calculation_method': 'rank_change_dynamic'
            }
            
        except Exception as e:
            raise ValueError(f"åŠ¨æ€æ¢æ‰‹ç‡è®¡ç®—å¤±è´¥ {factor_name}: {e}")

    #å¯åˆ é™¤
    def _estimate_factor_turnover(self, factor_name: str) -> Dict[str, float]:
        """
        ä¼°ç®—å› å­æ¢æ‰‹ç‡ (æ–¹æ¡ˆ1: åŸºäºç»éªŒå’Œå› å­ç±»å‹)
        
        Args:
            factor_name: å› å­åç§°
            
        Returns:
            Dict: æ¢æ‰‹ç‡ç›¸å…³ç»Ÿè®¡æŒ‡æ ‡
        """
        try:
            # æ ¹æ®å› å­ç±»å‹ä¼°ç®—æ¢æ‰‹ç‡ï¼ˆåŸºäºç»éªŒå’Œç ”ç©¶ï¼‰
            turnover_estimates = {
                # é«˜é¢‘ç±»å› å­ï¼ˆæŠ€æœ¯é¢ï¼‰
                'reversal_1d': 0.30, 'reversal_5d': 0.25, 'reversal_10d': 0.20, 'reversal_21d': 0.18,
                'momentum_20d': 0.18, 'rsi': 0.22, 'cci': 0.24, 'rsi_ç»è¿‡æ®‹å·®åŒ–': 0.22, 'cci_ç»è¿‡æ®‹å·®åŒ–': 0.24,
                'macd': 0.20, 'bollinger_position': 0.28, 'rsi_divergence': 0.26, 'pead': 0.23,
                
                # ä¸­é¢‘ç±»å› å­ï¼ˆä»·é‡ç»“åˆï¼‰
                'momentum_60d': 0.15, 'momentum_120d': 0.12, 'momentum_12_1': 0.10, 'momentum_6_1': 0.13, 'momentum_3_1': 0.16,
                'momentum_pct_60d': 0.15, 'sharpe_momentum_60d': 0.14, 'sw_l1_momentum_21d': 0.17,
                'volatility_40d': 0.16, 'volatility_90d': 0.14, 'volatility_120d': 0.12,
                'volatility_40d_ç»è¿‡æ®‹å·®åŒ–': 0.16, 'volatility_90d_ç»è¿‡æ®‹å·®åŒ–': 0.14, 'volatility_120d_ç»è¿‡æ®‹å·®åŒ–': 0.12,
                'atr_20d': 0.18,
                'amihud_liquidity': 0.14, 'turnover_rate_90d_mean': 0.16, 'turnover_rate_monthly_mean': 0.15,
                'turnover_rate_90d_mean-ç»è¿‡æ®‹å·®åŒ–': 0.16, 'turnover_rate_monthly_mean_ç»è¿‡æ®‹å·®åŒ–': 0.15,
                'ln_turnover_value_90d': 0.17, 'ln_turnover_value_90d_ç»è¿‡æ®‹å·®åŒ–': 0.17,
                'turnover_t1_div_t20d_avg': 0.19, 'bid_ask_spread': 0.21,
                
                # ä½é¢‘ç±»å› å­ï¼ˆåŸºæœ¬é¢ï¼‰
                'ep_ratio': 0.08, 'bm_ratio': 0.07, 'sp_ratio': 0.08, 'cfp_ratio': 0.09, 'pb_ratio': 0.08,
                'pe_ttm': 0.08, 'ps_ratio': 0.08, 'value_composite': 0.07,
                'roe_ttm': 0.06, 'gross_margin_ttm': 0.05, 'earnings_stability': 0.04, 'roa_ttm': 0.06,
                'total_revenue_growth_yoy': 0.07, 'net_profit_growth_yoy': 0.08, 'eps_growth': 0.08,
                'operating_revenue_growth': 0.07, 'gross_profit_margin': 0.05, 'operating_margin': 0.05,
                'net_margin': 0.05, 'ebit_margin': 0.05,
                
                # è§„æ¨¡å› å­ï¼ˆæä½é¢‘ï¼‰
                'log_circ_mv': 0.03, 'log_total_mv': 0.03, 'market_cap_weight': 0.02,
                
                # è´¨é‡å› å­ï¼ˆä½é¢‘ï¼‰
                'debt_to_assets': 0.05, 'current_ratio': 0.04, 'asset_turnover': 0.06,
                'quality_momentum': 0.09, 'operating_accruals': 0.07, 'inventory_turnover': 0.06,
                'receivables_turnover': 0.06, 'working_capital_turnover': 0.07
            }
            
            # åŸºç¡€æ¢æ‰‹ç‡ä¼°ç®—
            base_turnover = turnover_estimates.get(factor_name, 0.12)  # é»˜è®¤12%
            
            return {
                'avg_daily_rank_change': float(base_turnover),
                'daily_turnover_volatility': float(base_turnover * 0.3),  # æ³¢åŠ¨ç‡çº¦ä¸ºå‡å€¼çš„30%
                'daily_turnover_trend': 0.0,  # ç»éªŒä¼°ç®—æ— æ³•æä¾›è¶‹åŠ¿ä¿¡æ¯
                'calculation_method': 'factor_type_estimate'
            }
            
        except Exception as e:
            logger.debug(f"æ¢æ‰‹ç‡ä¼°ç®—å¤±è´¥ {factor_name}: {e}")
            return self._get_empty_turnover_stats()
    
    def _get_empty_turnover_stats(self) -> Dict[str, float]:
        """è¿”å›ç©ºçš„æ¢æ‰‹ç‡ç»Ÿè®¡"""
        return {
            'avg_daily_rank_change': 0.0,
            'daily_turnover_volatility': 0.0,
            'daily_turnover_trend': 0.0,
        }

    def _align_data(self, factor_data: pd.DataFrame, return_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """å¯¹é½å› å­å’Œæ”¶ç›Šæ•°æ®"""
        # æ‰¾åˆ°å…±åŒçš„æ—¶é—´å’Œè‚¡ç¥¨
        common_dates = factor_data.index.intersection(return_data.index)
        common_stocks = factor_data.columns.intersection(return_data.columns)

        aligned_factor = factor_data.loc[common_dates, common_stocks]
        aligned_return = return_data.loc[common_dates, common_stocks]

        return aligned_factor, aligned_return
    #è¿”å›æ¯ä¸ªæœˆæœ€åä¸€å¤©!
    def _generate_calculation_dates(self, start_date: str, end_date: str) -> List[str]:
        """ç”Ÿæˆè®¡ç®—æ—¶ç‚¹åºåˆ—"""
        dates = []
        current = pd.Timestamp(start_date)
        end = pd.Timestamp(end_date)

        # æ ¹æ®é¢‘ç‡ç”Ÿæˆæ—¶ç‚¹
        if self.config.calculation_frequency == 'M':
            # æœˆæœ«
            while current <= end:
                # æ‰¾åˆ°å½“æœˆæœ€åä¸€ä¸ªå·¥ä½œæ—¥
                month_end = current + pd.offsets.MonthEnd(0)
                if month_end <= end:
                    dates.append(month_end.strftime('%Y-%m-%d'))
                current = month_end + pd.offsets.MonthEnd(1)
        elif self.config.calculation_frequency == 'Q':
            # å­£æœ«
            while current <= end:
                quarter_end = current + pd.offsets.QuarterEnd(0)
                if quarter_end <= end:
                    dates.append(quarter_end.strftime('%Y-%m-%d'))
                current = current + pd.offsets.QuarterEnd(1)

        return dates

    def _snapshot_exists(self, factor_name: str, stock_pool: str, calculation_date: str) -> bool:
        """æ£€æŸ¥ICå¿«ç…§æ˜¯å¦å·²å­˜åœ¨"""
        snapshot_key = f"{factor_name}_{stock_pool}_{calculation_date}"
        return snapshot_key in self._ic_index

    def _save_snapshot(self, snapshot: ICSnapshot):
        """ä¿å­˜ICå¿«ç…§"""
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        snapshot_dir = self.main_work_path / snapshot.stock_pool_index / snapshot.factor_name / self.calcu_return_type / self.version / 'rolling_ic'
        snapshot_dir.mkdir(parents=True, exist_ok=True)

        filename = f"ic_snapshot_{snapshot.calculation_date}.json"
        filepath = snapshot_dir / filename

        # åºåˆ—åŒ–å¿«ç…§
        snapshot_dict = {
            'calculation_date': snapshot.calculation_date,
            'factor_name': snapshot.factor_name,
            'stock_pool_index': snapshot.stock_pool_index,
            'window_start': snapshot.window_start,
            'window_end': snapshot.window_end,
            'ic_stats': snapshot.ic_stats,
            'metadata': snapshot.metadata
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(snapshot_dict, f, ensure_ascii=False, indent=2)

        # æ›´æ–°ç´¢å¼•
        snapshot_key = f"{snapshot.factor_name}_{snapshot.stock_pool_index}_version_{self.version}_calculation_date_{snapshot.calculation_date}"
        self._ic_index[snapshot_key] = {
            'calculation_date': snapshot.calculation_date,
            'filepath': str(filepath),
            'created_at': datetime.now().isoformat()
        }

        self._save_ic_index()
        logger.debug(f"ICå¿«ç…§å·²ä¿å­˜: {filepath}")

    def _load_snapshot(self, factor_name: str, stock_pool_index: str, calculation_date: str) -> Optional[ICSnapshot]:
        """åŠ è½½ICå¿«ç…§"""
        snapshot_key =f'{factor_name}_{stock_pool_index}_version_{self.version}_calculation_date_{calculation_date}'

        if snapshot_key not in self._ic_index:
            return None

        try:
            filepath = self._ic_index[snapshot_key]['filepath']

            with open(filepath, 'r', encoding='utf-8') as f:
                snapshot_dict = json.load(f)

            return ICSnapshot(**snapshot_dict)

        except Exception as e:
            logger.error(f"åŠ è½½ICå¿«ç…§å¤±è´¥ {snapshot_key}: {e}")
            return None

    def _load_ic_index(self):
        """åŠ è½½ICç´¢å¼•"""
        index_file = self.main_work_path / "ic_index.json"

        if index_file.exists():
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    self._ic_index = json.load(f)
                logger.info(f"ICç´¢å¼•åŠ è½½å®Œæˆï¼Œå…± {len(self._ic_index)} æ¡è®°å½•")
            except Exception as e:
                raise ValueError(f"åŠ è½½ICç´¢å¼•å¤±è´¥: {e}")
        else:
            self._ic_index = {}

    def _save_ic_index(self):
        """ä¿å­˜ICç´¢å¼•"""
        index_file = self.main_work_path / "ic_index.json"

        try:
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(self._ic_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ICç´¢å¼•å¤±è´¥: {e}")

    def get_latest_calculation_date(self, factor_name: str, stock_pool: str) -> Optional[str]:
        """è·å–å› å­çš„æœ€æ–°è®¡ç®—æ—¶ç‚¹"""
        pattern = f"{factor_name}_{stock_pool}_"
        latest_date = None

        for key, metadata in self._ic_index.items():
            if key.startswith(pattern):
                calc_date = metadata['calculation_date']
                if latest_date is None or calc_date > latest_date:
                    latest_date = calc_date

        return latest_date

    def cleanup_old_snapshots(self, keep_months: int = 36):
        """æ¸…ç†è¿‡æœŸçš„ICå¿«ç…§"""
        cutoff_date = datetime.now() - relativedelta(months=keep_months)
        cutoff_str = cutoff_date.strftime('%Y-%m-%d')

        removed_count = 0
        keys_to_remove = []

        for key, metadata in self._ic_index.items():
            if metadata['calculation_date'] < cutoff_str:
                try:
                    # åˆ é™¤æ–‡ä»¶
                    filepath = Path(metadata['filepath'])
                    if filepath.exists():
                        filepath.unlink()

                    keys_to_remove.append(key)
                    removed_count += 1

                except Exception as e:
                    logger.error(f"åˆ é™¤å¿«ç…§å¤±è´¥ {key}: {e}")

        # æ›´æ–°ç´¢å¼•
        for key in keys_to_remove:
            del self._ic_index[key]

        self._save_ic_index()
        logger.info(f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤ {removed_count} ä¸ªè¿‡æœŸå¿«ç…§")


def run_cal_and_save_rolling_ic_by_snapshot_config_id(snapshot_config_id, factor_names):
    manager = ConfigSnapshotManager()
    pool_index,s,e ,config_evaluation= manager.get_snapshot_config_content_details(snapshot_config_id)
    version = f'{s}_{e}'
    config = ICCalculationConfig(
        lookback_months=12,
        forward_periods=config_evaluation['forward_periods'],
        min_require_observations=120,
        calculation_frequency='M'
    )
    if 'o2o' not in config_evaluation['returns_calculator']:
        raise ValueError("ä¹‹å‰çš„æµ‹è¯• è®¡ç®—æ”¶ç›Šç‡ä¸æ˜¯æŒ‰ç…§c2cæ¥çš„ï¼Œç°åœ¨æ— æ³•æ»šåŠ¨ ")
    manager = RollingICManager('o2o', config,version)

    resultLoadManager = ResultLoadManager(calcu_return_type='o2o', version=version,
                                          is_raw_factor=False)

    stock_pool_index = pool_index

    snapshots = manager.calculate_and_store_rolling_ic(
        factor_names, stock_pool_index, s, e,
        resultLoadManager, True
    )
    print(f"è®¡ç®—å®Œæˆï¼Œå…±ç”Ÿæˆ {sum(len(snaps) for snaps in snapshots.values())} ä¸ªICå¿«ç…§")
if __name__ == '__main__':
    # ä½¿ç”¨å¹¶å‘æ‰§è¡Œå™¨è¿›è¡Œæ‰¹é‡è®¡ç®—
    from projects._03_factor_selection.utils.efficiency_engineering.concurrent_executor import run_concurrent_factors
    
    snapshot_config_id = '20250906_045625_05e460ab'
    df = pd.read_csv(r'D:\lqs\codeAbout\py\Quantitative\quant_research_portfolio\projects\_03_factor_selection\factor_manager\selector\o2o_v3.csv')
    factor_names = df['factor_name'].unique().tolist()
    
    logger.info(f"ğŸ“Š å¼€å§‹æ‰¹é‡è®¡ç®— {len(factor_names)} ä¸ªå› å­çš„æ»šåŠ¨IC")
    factor_names = ['lqs_orthogonal_v1']
    # # å¹¶å‘æ‰§è¡Œ - å•å› å­æ¨¡å¼ï¼Œé€‚åˆå†…å­˜å……è¶³çš„æƒ…å†µ
    # successful_results, failed_factors = run_concurrent_factors(
    #     factor_names=factor_names,
    #     snapshot_config_id=snapshot_config_id,
    #     max_workers=3,  # æ ¹æ®æœºå™¨é…ç½®è°ƒæ•´
    #     execution_mode="chunked"  # æˆ– "chunked" ç”¨äºåˆ†ç»„æ‰§è¡Œ
    # )
    #
    # logger.info(f"ğŸ‰ æ‰¹é‡è®¡ç®—å®Œæˆ!")
    # logger.info(f"âœ… æˆåŠŸ: {len(successful_results)} ä¸ªå› å­")
    # logger.info(f"âŒ å¤±è´¥: {len(failed_factors)} ä¸ªå› å­")
    #
    # if failed_factors:
    #     logger.warning("å¤±è´¥çš„å› å­:")
    #     for factor, error in failed_factors:
    #         logger.warning(f"  - {factor}: {error}")
    
    # å•ä¸ªæµ‹è¯•ç”¨æ³•(ä¿ç•™åŸæœ‰æ–¹å¼)
    run_cal_and_save_rolling_ic_by_snapshot_config_id('20250909_125913_b5be5b49',['vwap_deviation_20d'] )