"""
å•å› å­æµ‹è¯•æ¡†æ¶ - ä¸“ä¸šç‰ˆ

å®ç°åæ³°è¯åˆ¸æ ‡å‡†çš„ä¸‰ç§å•å› å­æµ‹è¯•æ–¹æ³•ï¼š
1. ICå€¼åˆ†ææ³•
2. åˆ†å±‚å›æµ‹æ³•  
3. Fama-MacBethå›å½’æ³•ï¼ˆé»„é‡‘æ ‡å‡†ï¼‰

æ”¯æŒæ‰¹é‡æµ‹è¯•ã€ç»“æœå¯è§†åŒ–å’ŒæŠ¥å‘Šç”Ÿæˆ
"""
import os
import sys
import warnings
from datetime import datetime
from functools import partial
from pathlib import Path
from typing import Callable, Any, Optional, List
from typing import Dict, Tuple, Any

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from pandas import Series, DataFrame
from scipy import stats

from projects._03_factor_selection.config_manager.function_load.load_config_file import is_debug
from projects._03_factor_selection.factor_manager.factor_composite.factor_synthesizer import FactorSynthesizer
from projects._03_factor_selection.factor_manager.factor_manager import FactorResultsManager
from projects._03_factor_selection.utils.IndustryMap import PointInTimeIndustryMap
from projects._03_factor_selection.utils.factor_processor import FactorProcessor
from projects._03_factor_selection.visualization_manager import VisualizationManager
from quant_lib import logger
from quant_lib.config.logger_config import log_flow_start

n_metrics_pass_rate_key = 'n_metrics_pass_rate'

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from quant_lib.evaluation.evaluation import (
    calculate_ic,
    calculate_quantile_returns, fama_macbeth, calculate_turnover,
     quantile_stats_result,
    calculate_quantile_daily_returns, calculate_forward_returns_tradable_o2o

)

# # å¯¼å…¥æ–°çš„å¯è§†åŒ–ç®¡ç†å™¨
# try:
#     from visualization_manager import VisualizationManager
# except ImportError:
#     VisualizationManager = None

warnings.filterwarnings('ignore')


# ä½¿ç”¨æ—¶ æ³¨æ„shift
def prepare_industry_dummies(
        pit_map: PointInTimeIndustryMap,
        trade_dates: pd.DatetimeIndex,
        stock_codes: list,
        level: str = 'l1_code',  # æ¥æ”¶æ¥è‡ªé…ç½®çš„è¡Œä¸šçº§åˆ«
        drop_first: bool = True  # <--- æ–°å¢ä¸€ä¸ªå‚æ•°ï¼Œé»˜è®¤ä¸ºTrue

) -> Dict[str, pd.DataFrame]:
    """
    æ ¹æ®æŒ‡å®šçš„è¡Œä¸šçº§åˆ«ï¼Œä»PointInTimeIndustryMapç”Ÿæˆè¡Œä¸šå“‘å˜é‡DataFrameå­—å…¸ã€‚

    Args:
        pit_map: é¢„å¤„ç†å¥½çš„PointInTimeIndustryMapå®ä¾‹ã€‚
        trade_dates: æ•´ä¸ªå›æµ‹åŒºé—´çš„äº¤æ˜“æ—¥ç´¢å¼•ã€‚
        stock_codes: æ•´ä¸ªå›æµ‹åŒºé—´çš„è‚¡ç¥¨æ± åˆ—è¡¨ã€‚
        level: 'l1_code' æˆ– 'l2_code'ï¼ŒæŒ‡å®šè¡Œä¸šçº§åˆ«ã€‚

    Returns:
        ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸º 'industry_è¡Œä¸šä»£ç 'ï¼Œå€¼ä¸ºå¯¹åº”çš„å“‘å˜é‡DataFrame (index=date, columns=stock)ã€‚
    """
    # ã€åœ¨è¿™é‡ŒåŠ å…¥è¯Šæ–­ä»£ç ã€‘
    # print("\n" + "=" * 20 + " æ­£åœ¨è¯Šæ–­ trade_dates " + "=" * 20)
    # print(f"ä¼ å…¥çš„ trade_dates çš„ç±»å‹æ˜¯: {type(trade_dates)}")
    # æˆ‘ä»¬å°è¯•æ‰“å°å®ƒçš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œçœ‹çœ‹å®ƒåˆ°åº•æ˜¯ä»€ä¹ˆ
    # try:
    #     first_element = list(trade_dates)[0]
    #     print(f"trade_dates çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯: {first_element}")
    #     print(f"ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹æ˜¯: {type(first_element)}")
    # except IndexError:
    #     print("trade_dates ä¸ºç©ºï¼")
    # print("=" * 60 + "\n")
    # print(f"  æ­£åœ¨åŸºäº {level} ç”Ÿæˆè¡Œä¸šå“‘å˜é‡...")

    # 1. æ„å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰æ—¥æœŸå’Œè‚¡ç¥¨çš„â€œé•¿æ ¼å¼â€è¡Œä¸šåˆ†ç±»è¡¨
    all_daily_maps = []
    for date in trade_dates:
        daily_map = pit_map.get_map_for_date(date)
        if not daily_map.empty:
            daily_map = daily_map.reset_index()
            daily_map['date'] = date
            all_daily_maps.append(daily_map)

    if not all_daily_maps:
        return {}

    long_format_df = pd.concat(all_daily_maps)

    # 2. ä½¿ç”¨ pd.get_dummies é«˜æ•ˆç”Ÿæˆå“‘å˜é‡
    # prefix='industry' ä¼šè‡ªåŠ¨ç»™æ–°ç”Ÿæˆçš„åˆ—åŠ ä¸Š 'industry_' å‰ç¼€
    dummies = pd.get_dummies(
        long_format_df[level],
        prefix='industry',
        dtype=float,
        drop_first=drop_first  # <--- åº”ç”¨è¿™ä¸ªå‚æ•°
    )
    dummy_df = pd.concat([long_format_df[['date', 'ts_code']], dummies], axis=1)

    # ======================= ä¾¦æ¢å·¥å…· #1 å¼€å§‹ =======================
    # æ£€æŸ¥åœ¨ dummy_df ä¸­æ˜¯å¦å­˜åœ¨ (date, ts_code) çš„é‡å¤
    duplicates_mask = dummy_df.duplicated(subset=['date', 'ts_code'], keep=False)

    if duplicates_mask.any():
        print("â€¼ï¸  æ‰¾åˆ°äº†å¯¼è‡´ pivot å¤±è´¥çš„é‡å¤è®°å½•ï¼è¯¦æƒ…å¦‚ä¸‹ï¼š")

        # ç­›é€‰å‡ºæ‰€æœ‰é‡å¤çš„è®°å½•
        problematic_entries = dummy_df[duplicates_mask]

        # ä¸ºäº†çœ‹å¾—æ›´æ¸…æ¥šï¼Œæˆ‘ä»¬æŠŠåŸå§‹çš„è¡Œä¸šä»£ç ä¹ŸåŠ å›æ¥
        problematic_entries_with_industry = problematic_entries.merge(
            long_format_df[['date', 'ts_code', level]],
            on=['date', 'ts_code']
        )

        # æŒ‰ç…§è‚¡ç¥¨å’Œæ—¥æœŸæ’åºï¼Œæ–¹ä¾¿è§‚å¯Ÿ
        print(problematic_entries_with_industry.sort_values(by=['ts_code', 'date']))
    # 3. å°†é•¿æ ¼å¼çš„å“‘å˜é‡è¡¨è½¬æ¢ä¸ºæˆ‘ä»¬éœ€è¦çš„â€œå­—å…¸ of å®½æ ¼å¼DataFrameâ€
    # è¿™æ˜¯æ€§èƒ½å…³é”®ç‚¹ï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤é€è§†
    dummy_dfs = {}

    # è·å–æ‰€æœ‰å“‘å˜é‡çš„åˆ—åï¼Œä¾‹å¦‚ ['industry_801010.SI', 'industry_801020.SI', ...]
    industry_cols = [col for col in dummy_df.columns if col.startswith('industry_')]

    for col in industry_cols:
        # ä½¿ç”¨ pivot æ“ä½œå°†æ¯ä¸ªè¡Œä¸šå“‘å˜é‡åˆ—è½¬æ¢ä¸º Date x Stock çš„çŸ©é˜µ
        # fill_value=0 ç¡®ä¿æ²¡æœ‰è¯¥å…¬å¸æ²¡æœ‰è¯¥è¡Œä¸šåˆ†ç±»æ—¶ï¼Œå€¼ä¸º0
        pivoted_df = dummy_df.pivot(index='date', columns='ts_code', values=col).fillna(0)

        # ç¡®ä¿è¿”å›çš„DataFrameçš„ç´¢å¼•å’Œåˆ—ä¸å› å­æ•°æ®å®Œå…¨ä¸€è‡´
        dummy_dfs[col] = pivoted_df.reindex(index=trade_dates, columns=stock_codes).fillna(0)

    print(f"  æˆåŠŸç”Ÿæˆ {len(dummy_dfs)} ä¸ª {level} çº§åˆ«çš„è¡Œä¸šå“‘å˜é‡ã€‚")
    return dummy_dfs


def save_temp_date(target_factor_name,factor_data_shifted,returns_calculator,subfix):
    # å‡è®¾ final_factor_for_test æ˜¯æœ€ç»ˆå‡†å¤‡å¥½è¿›å…¥æµ‹è¯•çš„ T-1 å› å­
    final_factor_for_test = factor_data_shifted

    # â–¼â–¼â–¼â–¼â–¼ ã€ç»ˆæå®¡è®¡ä»£ç ã€‘åœ¨è¿™é‡Œè®¾ç½®â€œæµ·å…³æ£€æŸ¥ç«™â€ â–¼â–¼â–¼â–¼â–¼
    from pathlib import Path
    import sys

    # æˆ‘ä»¬åªå¯¹â€œå«Œç–‘äººâ€ volatility_90d çš„ raw æµ‹è¯•è¿›è¡Œæ‹¦æˆª
    if target_factor_name == 'volatility_120d' :

        debug_dir = Path('./debug_snapshot')
        debug_dir.mkdir(exist_ok=True)

        # 1. æ‰£æŠ¼â€œå«Œç–‘äººâ€ï¼šå³å°†è¿›å…¥æµ‹è¯•çš„ T-1 å› å­
        factor_path = debug_dir / f'factor_to_test_{subfix}.parquet'
        final_factor_for_test.to_parquet(factor_path)

        # 2. æ‰£æŠ¼â€œæ ‡å°ºâ€ï¼šè®¡ç®—æœªæ¥æ”¶ç›Šç‡æ‰€éœ€çš„ close_hfq_filled
        #    æˆ‘ä»¬å‡è®¾ returns_calculator æ˜¯ä¸€ä¸ª partial å‡½æ•°ï¼Œprice_df æ˜¯å®ƒçš„å…³é”®å­—å‚æ•°
        try:
            price_df_for_returns = returns_calculator.keywords['price_df']
            price_path = debug_dir / 'price_for_returns.parquet'
            price_df_for_returns.to_parquet(price_path)
            logger.info(f"--- [ç»ˆæå®¡è®¡] å·²å°†æµ‹è¯•å‰çš„æ•°æ®å¿«ç…§ä¿å­˜è‡³: {debug_dir.resolve()} ---")
        except (AttributeError, KeyError):
            logger.error("--- [ç»ˆæå®¡è®¡] æ— æ³•ä»returns_calculatorä¸­æå–price_dfã€‚")

        # 3. æ‹¦æˆªåç›´æ¥é€€å‡ºï¼Œæˆ‘ä»¬åªéœ€è¦è¿™ä»½â€œè¯ç‰©â€
        logger.info("--- [ç»ˆæå®¡è®¡] å·²è·å–å¿«ç…§ï¼Œç¨‹åºå°†ç»ˆæ­¢ã€‚---")
    # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²


class FactorAnalyzer:
    """
    å•å› å­(è´¨æ£€ä¸­å¿ƒ ICåˆ†æã€åˆ†å±‚å›æµ‹ã€F-Må›å½’ã€ç»˜å›¾ç­‰ï¼‰

    æŒ‰ç…§åæ³°è¯åˆ¸æ ‡å‡†å®ç°ä¸‰ç§æµ‹è¯•æ–¹æ³•çš„å®Œæ•´æµç¨‹
    """

    def __init__(self,
                 factor_manager,
                 target_factors_dict: Dict[str, pd.DataFrame] = None,
                 target_factors_category_dict: Dict[str, Any] = None,
                 target_factor_school_type_dict: Dict[str, Any] = None

                 ):
        """
        åˆå§‹åŒ–å•å› å­æµ‹è¯•å™¨ -
        """
        # å¿…è¦æ£€æŸ¥
        if not factor_manager:
            raise RuntimeError("config_manager æ²¡æœ‰ä¼ é€’è¿‡æ¥ï¼")
        self.factor_manager = factor_manager
        data_manager = factor_manager.data_manager
        if self.factor_manager.data_manager is None :
            raise ValueError('self.factor_manager.data_manager is Noneï¼')

        config = data_manager.config
        self.config = data_manager.config
        self.test_common_periods = self.config['evaluation'].get('forward_periods', [1, 5, 10, 20])
        self.n_quantiles = self.config.get('quantiles', 5)
        # åˆå§‹åŒ–å› å­é¢„å¤„ç†å™¨
        self.factor_processor = FactorProcessor(self.config)
        self.factorResultsManager = FactorResultsManager()
        self.stock_pools_dict = data_manager.stock_pools_dict

        # åˆå§‹åŒ–æ•°æ®

        self.target_factors_dict = target_factors_dict
        self.target_factors_style_category_dict = target_factors_category_dict
        self.target_school_type_dict = target_factor_school_type_dict

        self.backtest_start_date = config['backtest']['start_date']
        self.backtest_end_date = config['backtest']['end_date']
        self.backtest_period = f"{pd.to_datetime(self.backtest_start_date).strftime('%Y%m%d')} ~ {pd.to_datetime(self.backtest_end_date).strftime('%Y%m%d')}"

        # ã€ä¿®å¤ã€‘ä½¿ç”¨ç›¸å¯¹è·¯å¾„é¿å…ç¡¬ç¼–ç 
        project_root = Path(__file__).parent.parent.parent
        visualization_dir = project_root / 'workspace' / 'visualizations'
        visualization_dir.mkdir(parents=True, exist_ok=True)

        self.visualizationManager = VisualizationManager(
            output_dir=str(visualization_dir)
        )

        # å†³å®šå»¶è¿ŸåŠ è½½
        # self.master_beta_df = self.prepare_master_pct_chg_beta_dataframe()

        # åŸºäºä¸åŒè‚¡ç¥¨æ± ï¼ï¼ï¼
        # self.close_df_diff_stock_pools_dict = self.build_df_dict_base_on_diff_pool_can_set_shift(factor_name='close',need_shift=False)  # åªéœ€è¦å¯¹é½è‚¡ç¥¨å°±è¡Œ dict
        # self.circ_mv__shift_diff_stock_pools_dict = self.build_df_dict_base_on_diff_pool_can_set_shift(factor_name='circ_mv',need_shift=True)
        # self.pct_chg_beta_shift_diff_stock_pools_dict = self.build_df_dict_base_on_diff_pool_can_set_shift( base_dict=self.get_pct_chg_beta_dict(), factor_name='pct_chg', need_shift=True)

        # å‡†å¤‡è¾…åŠ©ã€å¸‚å€¼ã€è¡Œä¸šã€‘æ•°æ®(ç”¨äºä¸­æ€§å€¼ è®¡ç®—ï¼)
        # self.auxiliary_dfs_shift_diff_stock_polls_dict = self.build_auxiliary_dfs_shift_diff_stock_pools_dict()
        # self.prepare_for_neutral_dfs_shift_diff_stock_pools_dict = self.prepare_for_neutral_data_dict_shift_diff_stock_pools()
        # self.check_shape()

        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
        plt.rcParams['axes.unicode_minus'] = False

    def test_ic_analysis(self,
                         factor_data: pd.DataFrame,
                         returns_calculator: Callable[[int, pd.DataFrame, pd.DataFrame], pd.DataFrame],  # å…·ä½“åŒ–Callable
                         close_df: pd.DataFrame,
                         factor_name: str) -> Tuple[Dict[str, Series], Dict[str, pd.DataFrame]]:
        """
        ICå€¼åˆ†ææ³•æµ‹è¯•

        Args:
            factor_data: é¢„å¤„ç†åçš„å› å­æ•°æ®
            factor_name: å› å­åç§°


        Returns:
            ICåˆ†æç»“æœå­—å…¸
        """

        ic_series_periods_dict, stats_periods_dict = calculate_ic(factor_data, close_df,
                                                                  forward_periods=self.test_common_periods,
                                                                  method='spearman',
                                                                  returns_calculator=returns_calculator, min_stocks=30)

        return ic_series_periods_dict, stats_periods_dict
    def test_quantile_backtest(self,
                               factor_data: pd.DataFrame,
                               returns_calculator: Callable[[int, pd.DataFrame, pd.DataFrame], pd.DataFrame],
                               close_df: pd.DataFrame,
                               factor_name: str) -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:
        """
        åˆ†å±‚å›æµ‹æ³•æµ‹è¯•

        Args:
            factor_data: é¢„å¤„ç†åçš„å› å­æ•°æ®
            factor_name: å› å­åç§°

        Returns:
            åˆ†å±‚å›æµ‹ç»“æœå­—å…¸
        """
        # a) è·å–åˆ†å±‚ã€å‘¨æœŸã€‘æ”¶ç›Šç‡çš„æ—¶é—´åºåˆ—
        quantile_returns_periods_dict = calculate_quantile_returns(
            factor_data,
            returns_calculator,
            close_df,
            n_quantiles=self.n_quantiles,
            forward_periods=self.test_common_periods
        )

        quantile_returns_periods_dict, quantile_stats_periods_dict = quantile_stats_result(
            quantile_returns_periods_dict, self.n_quantiles)

        return quantile_returns_periods_dict, quantile_stats_periods_dict

    def test_turnover_result(self, factor_data):
        logger.info("    > æ­£åœ¨è®¡ç®—å› å­æ¢æ‰‹ç‡...")
        turnover_series_periods_dict = calculate_turnover(
            factor_df=factor_data,
            n_quantiles=self.n_quantiles,
            forward_periods=self.test_common_periods
        )
        turnover_stats_periods_dict = {}
        for period, turnover_series in turnover_series_periods_dict.items():
            turnover_stats_periods_dict[period] = {
                'turnover_mean': turnover_series.mean(),  # å‘¨æœŸå¹³å‡æ¢æ‰‹ç‡
                'turnover_annual': turnover_series.mean() * (252 / int(period[:-1]))  # å¹´åŒ–æ¢æ‰‹ç‡
                ##
                # å‡è®¾å¹³å‡æ¯å¤©10%çš„è‚¡ç¥¨å˜åŠ¨åˆ†ä½ç»„æ•°ã€‚
                # å‘¨æœŸ10å¤©
                # å¹´åŒ–ç®—å‡ºæ¥25.2
                # èµ„é‡‘æ¥å›æ»šåŠ¨25æ¬¡ æœ‰ç‚¹è´¹ç¨è´¹ï¼#
            }
        return turnover_stats_periods_dict

    # def test_fama_macbeth(self,
    #                       factor_data: pd.DataFrame,
    #                       close_df: pd.DataFrame,
    #                       neutral_dfs: dict[str, pd.DataFrame],
    #                       circ_mv_df: pd.DataFrame,
    #                       factor_name: str) -> Tuple[Dict[str, pd.DataFrame],Dict[str, pd.DataFrame]]:
    #     return test_fama_macbeth(factor_data=factor_data, close_df=close_df, neutral_dfs=neutral_dfs,
    #                       circ_mv_df=circ_mv_df,
    #                       factor_name=factor_name)
    # çº¯æµ‹è¯•ç»“æœ
    def comprehensive_test(self,
                           target_factor_name: str = None,
                           factor_data_shifted: pd.DataFrame = None,
                           stock_pool_index_name: str = None,
                           preprocess_method: str = "standard",
                           returns_calculator: Callable = None,
                           start_date: str = None, end_date: str = None,
                           need_process_factor: bool = True,
                           do_ic_test: bool = True, do_turnover_test: bool = True, do_quantile_test: bool = True,
                           do_fama_test: bool = True, do_style_correlation_test: bool = True,
                           ) -> Tuple[
        pd.DataFrame,Optional[Dict[str, pd.Series]],Optional[Dict[str, pd.DataFrame]],Optional[Dict[str, pd.DataFrame]],
        Optional[Dict[str, pd.DataFrame]],Optional[pd.DataFrame],Optional[Dict[str, pd.DataFrame]],
        Optional[Dict[str, pd.DataFrame]],Optional[Dict[str, pd.DataFrame]], Optional[Dict[str, pd.DataFrame]],Optional[Dict[str, float]]
    ]:
        """
        ç»¼åˆæµ‹è¯• - æ‰§è¡Œæ‰€æœ‰ä¸‰ç§æµ‹è¯•æ–¹æ³•

        Args:
        Returns:
            ç»¼åˆæµ‹è¯•ç»“æœå­—å…¸
        """

        logger.info(f"å¼€å§‹æµ‹è¯•å› å­: {target_factor_name}")



        # target_school = self.factor_manager.get_school_code_by_factor_name(target_factor_name)
        trade_dates =factor_data_shifted.index
        stock_codes = factor_data_shifted.columns

        # ç”Ÿæˆt-1çš„æ•°æ® ç”¨äºå› å­é¢„å¤„ç†
        (final_neutral_dfs, style_category
         ) = self.prepare_date_for_process_factor(target_factor_name, trade_dates,stock_codes,stock_pool_index_name)
        # save_temp_date(target_factor_name,factor_data_shifted,returns_calculator,'_raw')

        #ok æ£€æŸ¥åˆ°è¿™é‡Œä¸€åˆ‡æ­£å¸¸
        if need_process_factor:
            # 1. å®Œæ•´å› å­é¢„å¤„ç†ï¼ˆå»æå€¼ + ä¸­æ€§åŒ– + æ ‡å‡†åŒ–ï¼‰
            factor_data_shifted = self.factor_processor.process_factor(
                factor_df_shifted=factor_data_shifted,
                target_factor_name=target_factor_name,
                neutral_dfs=final_neutral_dfs,  # <--- ä¼ å…¥æƒå¨çš„ä¸­æ€§åŒ–æ•°æ®ç¯®å­
                style_category=style_category,
                pit_map=self.factor_manager.data_manager.pit_map,
                need_standardize = True
            )
        else:
            # 2. åŸå§‹å› å­çš„æœ€å°é¢„å¤„ç†ï¼ˆä»…å»æå€¼ï¼Œä¿æŒåŸå§‹ç‰¹å¾ï¼‰
            factor_data_shifted = self._minimal_preprocessing_for_raw_factor(
                factor_data_shifted, target_factor_name
            )

        # æ•°æ®å‡†å¤‡
        close_df, circ_mv_df_shifted, style_factor_dfs = self.prepare_date_for_core_test(target_factor_name,stock_pool_index_name)
        status_text = "éœ€è¦" if need_process_factor else "ä¸éœ€è¦"
        log_flow_start(
            f"å› å­ {target_factor_name}ï¼ˆ{status_text}ï¼‰ç»è¿‡é¢„å¤„ç†ï¼Œè¿›å…¥ core_three_test æµ‹è¯•"
        )
        # save_temp_date(target_factor_name,factor_data_shifted,returns_calculator,'_prcessed')
        ic_s, ic_st, q_r,q_daily_returns_df, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict \
            = self.core_three_test(
            factor_data_shifted, target_factor_name, returns_calculator, close_df,
            final_neutral_dfs, circ_mv_df_shifted, style_factor_dfs, do_ic_test,
            do_turnover_test,
            do_quantile_test, do_fama_test, do_style_correlation_test)

        return factor_data_shifted, ic_s, ic_st, q_r,q_daily_returns_df, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict

    def _minimal_preprocessing_for_raw_factor(self, factor_df: pd.DataFrame, factor_name: str) -> pd.DataFrame:
        """
        å¯¹åŸå§‹å› å­è¿›è¡Œæœ€å°å¿…è¦çš„é¢„å¤„ç†
        åªå»æå€¼ï¼Œä¸åšä¸­æ€§åŒ–å’Œæ ‡å‡†åŒ–ï¼Œä¿æŒå› å­çš„åŸå§‹ç‰¹å¾
        """
        logger.info(f"ğŸ”§ å¯¹åŸå§‹å› å­ {factor_name} è¿›è¡Œæœ€å°é¢„å¤„ç†ï¼ˆä»…å»æå€¼ï¼‰")

        # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦å»æå€¼
        factor_flat = factor_df.stack().dropna()

        # è®¡ç®—æå€¼æ¯”ä¾‹
        q01 = factor_flat.quantile(0.01)
        q99 = factor_flat.quantile(0.99)
        outlier_ratio = ((factor_flat < q01) | (factor_flat > q99)).mean()

        if outlier_ratio > 0.02:  # å¦‚æœæå€¼æ¯”ä¾‹è¶…è¿‡2%

            # 2. æŒ‰æ—¥æœŸè¿›è¡Œå»æå€¼ï¼ˆä¿æŒæˆªé¢å†…çš„ç›¸å¯¹å…³ç³»ï¼‰
            processed_df = factor_df.copy()
            for date in factor_df.index:
                daily_values = factor_df.loc[date].dropna()
                if len(daily_values) > 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
                    # ä½¿ç”¨1%å’Œ99%åˆ†ä½æ•°è¿›è¡Œwinsorize
                    lower_bound = daily_values.quantile(0.01)
                    upper_bound = daily_values.quantile(0.99)
                    processed_df.loc[date] = daily_values.clip(lower=lower_bound, upper=upper_bound)

            logger.info(f"  âœ… ğŸ“Šå»æ‰{outlier_ratio:.1%} çš„æå€¼ï¼Œä¿æŒå› å­åŸå§‹åˆ†å¸ƒç‰¹å¾")
            return processed_df
        else:
            logger.info(f"  âœ… æå€¼æ¯”ä¾‹è¾ƒä½({outlier_ratio:.1%})ï¼Œæ— éœ€å¤„ç†")
            return factor_df

    def evaluation_score_dict(self,
                              ic_stats_periods_dict,
                              quantile_stats_periods_dict,
                              fm_stat_results_periods_dict
                              ) -> Dict[str, Any]:

        ret = {}
        for period in self.test_common_periods:
            ret[f'{period}d'] = self._evaluate_factor_score(f'{period}d', ic_stats_periods_dict,
                                                            quantile_stats_periods_dict,
                                                            fm_stat_results_periods_dict)
        return ret

    def _evaluate_factor_score(self,
                               main_period: str,
                               ic_results: Dict,
                               quantile_results: Dict,
                               fm_results: Dict) -> Dict[str, Any]:
        """
        ç»¼åˆè¯„ä»·å› å­è¡¨ç°
        """

        # ICè¯„ä»·
        ic_main = ic_results.get(main_period, {})
        cal_score_ic = self.cal_score_ic(ic_main.get('ic_mean'),
                                         ic_main.get('ic_ir'),
                                         ic_main.get('ic_win_rate'),
                                         ic_main.get('ic_p_value')
                                         )

        # åˆ†å±‚å›æµ‹è¯„ä»·
        quantile_main = quantile_results.get(main_period, {})

        cal_score_quantile = self.cal_score_quantile_performance(quantile_main)

        # Fama-MacBethè¯„ä»·
        fm_main = fm_results.get(main_period, {})
        cal_score_fama_macbeth = self.cal_score_fama_macbeth(fm_main)

        # ç»¼åˆè¯„åˆ†
        cal_score_factor_holistically = self.cal_score_factor_holistically(cal_score_ic, cal_score_quantile,
                                                                           cal_score_fama_macbeth)
        return cal_score_factor_holistically

    # è¿™æ˜¯æœ€åŸå§‹çš„è¯„æµ‹ï¼Œå¾ˆä¸å‡†ï¼ ä¸è¦å‚è€ƒscoreï¼Œåªçœ‹çœ‹åº•å±‚çš„åŸºæœ¬æ•°æ®å°±è¡Œï¼ æœ€åçš„calculate_factor_scoreæ˜¯æœ€æƒå¨çš„
    def overrall_summary(self, results: Dict[str, Any]):

        ic_analysis_dict = results['ic_analysis']
        quantile_backtest_dict = results['quantile_backtest']
        fama_macbeth_dict = results['fama_macbeth']
        evaluation_dict = results['evaluate_factor_score']
        rows = []
        total_score = []
        flatten_metrics_dict = {}

        for day, evaluation in evaluation_dict.items():
            cur_total_score = evaluation['final_score']
            total_score.append(cur_total_score)
            # æ‰å¹³åŒ–çš„æ ¸å¿ƒæŒ‡æ ‡å­—æ®µ
            flatten_metrics_dict[f'{day}_ç»¼åˆè¯„åˆ†'] = cur_total_score
            sub = evaluation['sub']

            row = {

                'æŒæœ‰æœŸ': day,
                f'{day}_ç»¼åˆè¯„åˆ†': cur_total_score,
                'æ€»ç­‰çº§': evaluation['final_grade'],
                'ç»“è®º': evaluation['conclusion'],
                #
                f'IC_{day}å†…éƒ¨å¤šæŒ‡æ ‡é€šè¿‡ç‡': sub['IC'][n_metrics_pass_rate_key],
                f'Quantile_{day}å†…éƒ¨å¤šæŒ‡æ ‡é€šè¿‡ç‡': sub['Quantile'][n_metrics_pass_rate_key],
                f'FM_{day}å†…éƒ¨å¤šæŒ‡æ ‡é€šè¿‡ç‡': sub['Fama-MacBeth'][n_metrics_pass_rate_key],

                f'IC_{day}å†…éƒ¨å¤šæŒ‡æ ‡è¯„çº§': sub['IC']['grade'],
                f'Quantile_{day}å†…éƒ¨å¤šæŒ‡æ ‡è¯„çº§': sub['Quantile']['grade'],
                f'FM_{day}å†…éƒ¨å¤šæŒ‡æ ‡è¯„çº§': sub['Fama-MacBeth']['grade'],

                'ICåˆ†ææ‘˜è¦': ic_analysis_dict[day],
                'Quantileåˆ†ææ‘˜è¦': quantile_backtest_dict[day],
                'FMåˆ†ææ‘˜è¦': fama_macbeth_dict[day]
            }
            merged_row = {**row}
            rows.append(merged_row)
        backtest_period = f'{self.backtest_start_date}~{self.backtest_end_date}'
        return {results['factor_name']:
                    {'æµ‹è¯•æ—¥æœŸ': results['test_date'],
                     'å›æµ‹å‘¨æœŸ': backtest_period,
                     'best_score': max(total_score), **flatten_metrics_dict,
                     'diff_day_perform': rows}}

    def cal_score_ic(self,
                     ic_mean: float,
                     ic_ir: float,
                     ic_win_rate: float,
                     ic_p_value: float) -> Dict:
        """
        ã€ä¸“ä¸šç‰ˆã€‘å¯¹ICè¿›è¡Œå¤šç»´åº¦ã€åˆ†çº§ã€åŠ æƒè¯„åˆ†
        """

        # 1. ç§‘å­¦æ€§æ£€éªŒ (å‡†å…¥é—¨æ§›)
        is_significant = ic_p_value is not None and ic_p_value < 0.05

        # 2. åˆ†çº§è¯„åˆ†
        icir_score = 0
        if abs(ic_ir) > 0.5:
            icir_score = 2
        elif abs(ic_ir) > 0.3:
            icir_score = 1

        mean_score = 1 if abs(ic_mean) > 0.025 else 0
        win_rate_score = 1 if ic_win_rate > 0.55 else 0

        # 3. è®¡ç®—æ€»åˆ† (æ»¡åˆ†4åˆ†)
        total_score = icir_score + mean_score + win_rate_score

        # 4. ç”Ÿæˆè¯„çº§å’Œç»“è®º
        if not is_significant:
            grade = "D (ä¸æ˜¾è‘—)"
            conclusion = "å› å­æœªé€šè¿‡æ˜¾è‘—æ€§æ£€éªŒï¼Œç»“æœå¯èƒ½ç”±è¿æ°”å¯¼è‡´ï¼Œä¸äºˆé‡‡çº³ã€‚"
        elif total_score == 4:
            grade = "A+ (ä¼˜ç§€ï¼ˆ100%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
            conclusion = "æ‰€æœ‰æŒ‡æ ‡å‡è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¯é¡¶çº§çš„Alphaå› å­ã€‚"
        elif total_score == 3:
            grade = "A (è‰¯å¥½ï¼ˆ75%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
            conclusion = "æ ¸å¿ƒæŒ‡æ ‡è¡¨ç°è‰¯å¥½ï¼Œå…·å¤‡å¾ˆå¼ºçš„å®æˆ˜ä»·å€¼ã€‚"
        elif total_score == 2:
            grade = "B (åŠæ ¼ï¼ˆ50%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
            conclusion = "éƒ¨åˆ†æŒ‡æ ‡è¾¾æ ‡ï¼Œå› å­å…·å¤‡ä¸€å®šæœ‰æ•ˆæ€§ï¼Œå¯ä½œä¸ºå¤‡é€‰ã€‚"
        else:
            grade = "C (è¾ƒå·®)"
            conclusion = "æ ¸å¿ƒæŒ‡æ ‡è¡¨ç°ä¸ä½³ï¼Œå»ºè®®ä¼˜åŒ–æˆ–æ”¾å¼ƒã€‚"

        return {
            'n_metrics_pass_rate': total_score / 4,
            'grade': grade,
            'is_significant': is_significant,
            'details': {
                'ICIR': f"{ic_ir:.2f} (å¾—åˆ†:{icir_score})/(å…±è®¡ä¸¤åˆ†ã€‚ä¸€åˆ†å°±ä¹Ÿå¾ˆä¸é”™äº†)",
                'IC Mean': f"{ic_mean:.3f} (å¾—åˆ†:{mean_score})",
                'Win Rate': f"{ic_win_rate:.2%} (å¾—åˆ†:{win_rate_score})"
            },
            'conclusion': conclusion
        }

    def cal_score_quantile_performance(self, quantile_main: Dict) -> Dict[str, Any]:
        """
        ã€ä¸“ä¸šç‰ˆã€‘å¯¹åˆ†å±‚å›æµ‹ç»“æœè¿›è¡Œå¤šç»´åº¦ã€åˆ†çº§ã€åŠ æƒè¯„åˆ†ã€‚
        """
        # --- 1. æå–æ ¸å¿ƒæŒ‡æ ‡ ---
        quantile_means = quantile_main.get('quantile_means', [])
        tmb_sharpe = quantile_main.get('tmb_sharpe', 0)
        tmb_annual_return = quantile_main.get('tmb_annual_return', 0)
        # æœ€å¤§å›æ’¤é€šå¸¸æ˜¯è´Ÿæ•°ï¼Œæˆ‘ä»¬å–ç»å¯¹å€¼
        max_drawdown = abs(quantile_main.get('max_drawdown', 1.0))

        # --- 2. åˆ†çº§è¯„åˆ† ---

        # a) TMBå¤æ™®è¯„åˆ† (æ ¸å¿ƒæŒ‡æ ‡, æ»¡åˆ†2åˆ†)
        sharpe_score = 0
        if tmb_sharpe > 1.0:
            sharpe_score = 2
        elif tmb_sharpe > 0.5:
            sharpe_score = 1

        # b) å•è°ƒæ€§è¯„åˆ† (ç»“æ„æŒ‡æ ‡, æ»¡åˆ†1åˆ†)
        monotonicity_score = 0
        monotonicity_corr = np.nan
        if quantile_means and len(quantile_means) > 1:
            # ä½¿ç”¨spearmanç§©ç›¸å…³ç³»æ•°è®¡ç®—å•è°ƒç¨‹åº¦
            monotonicity_corr, _ = stats.spearmanr(quantile_means, range(len(quantile_means)))
            if monotonicity_corr > 0.8:
                monotonicity_score = 1

        # c) æ”¶ç›Š/é£æ§è¯„åˆ† (å®æˆ˜æŒ‡æ ‡, æ»¡åˆ†2åˆ†)
        # è®¡ç®—å¡ç›æ¯”ç‡ (Calmar Ratio)
        calmar_ratio = tmb_annual_return / max_drawdown if max_drawdown > 0 else 0

        risk_return_score = 0
        if calmar_ratio > 0.5 and tmb_annual_return > 0.05:
            risk_return_score = 2
        elif calmar_ratio > 0.2 and tmb_annual_return > 0.03:
            risk_return_score = 1

        # --- 3. æ±‡æ€»ä¸è¯„çº§ (æ€»åˆ†5åˆ†) ---
        total_score = sharpe_score + monotonicity_score + risk_return_score

        if total_score == 5:
            grade = "A+ (å¼ºçƒˆæ¨èï¼ˆ100%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
        elif total_score == 4:
            grade = "A (ä¼˜ç§€ï¼ˆ80%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
        elif total_score == 3:
            grade = "B (è‰¯å¥½-ï¼ˆ60%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
        elif total_score == 2:
            grade = "C (ä¸€èˆ¬ï¼ˆ40%æŒ‡æ ‡è¾¾åˆ°ï¼‰)"
        else:
            grade = "D (ä¸€èˆ¬ï¼ˆ0%~40%ï¼‰)"

        return {
            'n_metrics_pass_rate': total_score / 5,
            'grade': grade,
            'details': {
                'TMB Sharpe': f"{tmb_sharpe:.2f} (å¾—åˆ†:{sharpe_score})",
                'Monotonicity Corr': f"{monotonicity_corr:.2f} (å¾—åˆ†:{monotonicity_score})",
                'Calmar Ratio': f"{calmar_ratio:.2f} (å¾—åˆ†:{risk_return_score})",
                'TMB Annual Return': f"{tmb_annual_return:.2%}",
                'Max Drawdown': f"{max_drawdown:.2%}"
            },
            'conclusion': grade

        }

    def cal_score_fama_macbeth(self, fm_main: Dict) -> Dict[str, Any]:
        """
        ã€ä¸“ä¸šç‰ˆã€‘å¯¹Fama-MacBethå›å½’è¿›è¡Œå¤šç»´åº¦ã€åˆ†ç¦»å¼è¯„åˆ†
        """
        # --- 1. æå–æ ¸å¿ƒæŒ‡æ ‡ ---
        n_metrics_pass_rate = 0
        t_stat = fm_main.get('t_statistic', 0)
        mean_return = fm_main.get('mean_factor_return', 0)  # è¿™æ˜¯å‘¨æœŸå¹³å‡æ”¶ç›Š
        num_periods = fm_main.get('num_valid_periods', 0)
        success_rate = fm_main.get('success_rate', 0)
        factor_returns_series = fm_main.get('factor_returns_series', pd.Series(dtype=float))

        # --- 2. åˆ†ç¦»å¼è¯„åˆ† ---

        # a) æµ‹è¯•å¯ä¿¡åº¦è¯„åˆ† (æ»¡åˆ†3åˆ†)
        confidence_score = 0
        # å®Œæ•´åº¦è¯„åˆ† (0-1åˆ†)
        if success_rate >= 0.8: confidence_score += 1
        # å‘¨æœŸé•¿åº¦è¯„åˆ† (0-2åˆ†)
        if num_periods >= 252 * 3:
            confidence_score += 2
        elif num_periods >= 252:
            confidence_score += 1

        # b) å› å­æœ‰æ•ˆæ€§è¯„åˆ† (æ»¡åˆ†5åˆ†)
        performance_score = 0
        # æ˜¾è‘—æ€§è¯„åˆ† (0-3åˆ†)
        if not np.isnan(t_stat):
            if abs(t_stat) > 2.58:
                performance_score += 3
            elif abs(t_stat) > 1.96:
                performance_score += 2
            elif abs(t_stat) > 1.64:
                performance_score += 1

        # æ”¶ç›Šç¨³å®šæ€§è¯„åˆ† (Lambdaèƒœç‡, 0-1åˆ†)
        lambda_win_rate = 0
        if not factor_returns_series.empty:
            if factor_returns_series.mean() >= 0:
                lambda_win_rate = (factor_returns_series > 0).mean()
            else:
                lambda_win_rate = (factor_returns_series < 0).mean()
            if lambda_win_rate > 0.55:
                performance_score += 1

        # ç»æµæ„ä¹‰è¯„åˆ† (å¹´åŒ–æ”¶ç›Š, 0-1åˆ†)
        # å‡è®¾ daily period_len = 1, weekly = 5, etc.
        # è¿™é‡Œæˆ‘ä»¬ç®€å•å‡è®¾ä¸€ä¸ªå‘¨æœŸæ˜¯252/num_periodså¹´
        annualized_return = mean_return * (252 / self.test_common_periods[0])  # ç®€åŒ–å¤„ç†ï¼Œå‡è®¾å‘¨æœŸå›ºå®š
        if abs(annualized_return) > 0.03:  # å¹´åŒ–å› å­æ”¶ç›Šè¶…è¿‡3%
            performance_score += 1

        final_grade = "D"
        conclusion = "å› å­è¡¨ç°ä¸ä½³ã€‚"
        # ç»¼åˆè¯„çº§ - --
        # a) è®¾ç«‹â€œä¸€ç¥¨å¦å†³â€çº¢çº¿
        if confidence_score == 0 or success_rate <= 0.75:
            final_grade = "F (æµ‹è¯•ä¸å¯ä¿¡)"
            conclusion = "æµ‹è¯•è´¨é‡å®Œå…¨ä¸è¾¾æ ‡ (æ•´ç†æ•°æ®å å‚ä¸å›å½’ç‡è¿‡ä½ï¼šmaybeï¼šå‘¨æœŸè¿‡çŸ­ä¸”æ•°æ®ä¸å®Œæ•´)ã€‚"
        else:
            # b) æ ¹æ®è¡¨ç°åˆ†ï¼Œç¡®å®šåŸºç¡€è¯„çº§
            base_grade = "D"
            if performance_score >= 4:
                base_grade = "A"
                conclusion = "å› å­è¡¨ç°ä¼˜ç§€ï¼Œå…·å¤‡å¾ˆå¼ºçš„Alphaã€‚"
            elif performance_score >= 3:
                base_grade = "B"
                conclusion = "å› å­è¡¨ç°è‰¯å¥½ï¼Œå…·å¤‡ä¸€å®šAlphaã€‚"
            elif performance_score >= 2:
                base_grade = "C"
                conclusion = "å› å­è¡¨ç°ä¸€èˆ¬ï¼Œéœ€è¿›ä¸€æ­¥è§‚å¯Ÿã€‚"

            # c) æ ¹æ®å¯ä¿¡åº¦åˆ†ï¼Œè¿›è¡Œè°ƒæ•´å¹¶åŠ æ³¨
            if confidence_score == 3:
                final_grade = base_grade + "+" if base_grade in ["A", "B"] else base_grade
                conclusion += " æµ‹è¯•ç»“æœå…·æœ‰æé«˜å¯ä¿¡åº¦ã€‚"
            elif confidence_score == 2:
                final_grade = base_grade
                conclusion += " æµ‹è¯•ç»“æœå¯ä¿¡åº¦è‰¯å¥½ã€‚"
            elif confidence_score == 1:
                # å¯ä¿¡åº¦è¾ƒä½ï¼Œä¸‹è°ƒè¯„çº§
                if base_grade == "A":
                    final_grade = "B+"
                elif base_grade == "B":
                    final_grade = "C+"
                else:
                    final_grade = base_grade  # Cå’ŒDä¸å†ä¸‹è°ƒ
                conclusion += " [è­¦å‘Š] æµ‹è¯•å¯ä¿¡åº¦è¾ƒä½ï¼Œå¯èƒ½å› å‘¨æœŸè¾ƒçŸ­ï¼Œç»“è®ºéœ€è°¨æ…å¯¹å¾…ã€‚"
        grade_to_score_map = {
            'A+': 1.00,
            'A': 0.95,
            'B+': 0.90,
            'B': 0.80,
            'C+': 0.70,
            'C': 0.50,
            'D': 0.30,
            'F (æµ‹è¯•ä¸å¯ä¿¡)': 0.00  # æ˜ç¡®å¤„ç†Fè¯„çº§
        }
        n_metrics_pass_rate = grade_to_score_map.get(final_grade, 0.0)

        return {
            'n_metrics_pass_rate': n_metrics_pass_rate,
            'confidence_score': f"{confidence_score}/3",
            'performance_score': f"{performance_score}/5",
            'grade': final_grade,
            'conclusion': conclusion,
            'details': {
                't-statistic': f"{t_stat:.2f}",
                'Annualized Factor Return': f"{annualized_return:.2%}",
                'Lambda Win Rate': f"{lambda_win_rate:.2%}",
                'Valid Periods': num_periods,
                'Regression Success Rate': f"{success_rate:.2%}"
            }
        }

    def cal_score_factor_holistically(self,
                                      score_ic_eval: Dict,
                                      score_quantile_eval: Dict,
                                      score_fm_eval: Dict) -> Dict[str, Any]:
        """
        ã€æœ€ç»ˆæŠ•å†³ä¼šã€‘ç»¼åˆICã€åˆ†å±‚å›æµ‹ã€Fama-MacBethä¸‰å¤§æ£€éªŒç»“æœï¼Œå¯¹å› å­è¿›è¡Œæœ€ç»ˆè¯„çº§ã€‚
        """

        # --- 1. æå–å„æ¨¡å—çš„æ ¸å¿ƒè¯„ä»·ç»“æœ ---
        ic_n_metrics_pass_rate = score_ic_eval.get(n_metrics_pass_rate_key, 0)
        quantile_n_metrics_pass_rate = score_quantile_eval.get(n_metrics_pass_rate_key, 0)
        fm_n_metrics_pass_rate = score_fm_eval.get(n_metrics_pass_rate_key, 0)
        ic_is_significant = score_ic_eval.get('is_significant', False)

        quantile_grade = score_quantile_eval.get('grade', 'D')
        tmb_sharpe = score_quantile_eval.get('details', {}).get('TMB Sharpe', '0 (å¾—åˆ†:0)').split(' ')[0]

        fm_performance_score_str = score_fm_eval.get('performance_score', '0/5')
        fm_confidence_score_str = score_fm_eval.get('confidence_score', '0/3')
        fm_grade = score_fm_eval.get('grade', '')

        # --- 2. è§£ææ•°å€¼åˆ†æ•° ---
        try:
            fm_performance_score = int(fm_performance_score_str.split('/')[0])
            fm_confidence_score = int(fm_confidence_score_str.split('/')[0])
            tmb_sharpe = float(tmb_sharpe)
        except (ValueError, IndexError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¯´æ˜å­æŠ¥å‘Šæœ‰é—®é¢˜ï¼Œç›´æ¥è¿”å›é”™è¯¯
            return {'final_grade': 'F (é”™è¯¯)', 'conclusion': 'ä¸€ä¸ªæˆ–å¤šä¸ªå­è¯„ä¼°æŠ¥å‘Šæ ¼å¼é”™è¯¯ï¼Œæ— æ³•è¿›è¡Œç»¼åˆè¯„ä»·ã€‚'}

        # --- 3. æ‰§è¡Œâ€œä¸€ç¥¨å¦å†³â€è§„åˆ™ ---
        deal_breaker_reason = []
        if not ic_is_significant:
            deal_breaker_reason.append("ICæ£€éªŒä¸æ˜¾è‘—ï¼Œå› å­æœ‰æ•ˆæ€§æ— ç»Ÿè®¡å­¦æ”¯æŒã€‚")
        elif fm_grade == 'F':  # æœ€æ‹‰è·¨çš„åˆ†ï¼
            deal_breaker_reason.append(f"Fama-MacBethæ£€éªŒå¯ä¿¡åº¦ä½(å¾—åˆ†:{fm_confidence_score}/3)ï¼Œç»“æœä¸å¯é ã€‚")
        elif tmb_sharpe < 0:
            deal_breaker_reason.append(f"åˆ†å±‚å›æµ‹å¤šç©ºå¤æ™®æ¯”ç‡ä¸ºè´Ÿ({tmb_sharpe:.2f})ï¼Œå› å­åœ¨ç­–ç•¥å±‚é¢æ— æ•ˆã€‚")

        if deal_breaker_reason:
            return {
                'final_grade': 'F (å¦å†³)',
                'final_score': '0/100',
                'conclusion': f"å› å­å­˜åœ¨è‡´å‘½ç¼ºé™·: {deal_breaker_reason}",
                'sub': {
                    'IC': {"grade": score_ic_eval.get('grade'), n_metrics_pass_rate_key: ic_n_metrics_pass_rate},
                    'Quantile': {"grade": quantile_grade, n_metrics_pass_rate_key: quantile_n_metrics_pass_rate},
                    'Fama-MacBeth': {"grade": fm_grade, n_metrics_pass_rate_key: fm_n_metrics_pass_rate}
                }
            }

        # --- 4. è¿›è¡ŒåŠ æƒè¯„åˆ† (æ€»åˆ†100åˆ†) ---
        # æƒé‡åˆ†é…: åˆ†å±‚å›æµ‹(40%), F-M(35%), IC(25%)
        ic_max_score = 4
        quantile_max_score = 5
        fm_max_score = 5

        weighted_score = (
                ic_n_metrics_pass_rate * 25 +
                quantile_n_metrics_pass_rate * 40 +
                fm_n_metrics_pass_rate * 35
        )

        # --- 5. ç»™å‡ºæœ€ç»ˆè¯„çº§å’Œç»“è®º ---
        final_grade = ""
        conclusion = ""
        if weighted_score >= 85:
            final_grade = "S (æ——èˆ°çº§)"
            conclusion = "å› å­åœ¨æ‰€æœ‰ç»´åº¦å‡è¡¨ç°å“è¶Šï¼Œæ˜¯æå…¶ç½•è§çš„é¡¶çº§Alphaï¼Œåº”ä½œä¸ºç­–ç•¥æ ¸å¿ƒã€‚ "
        elif weighted_score >= 70:
            final_grade = "A (æ ¸å¿ƒå¤‡é€‰)"
            conclusion = "å› å­è¡¨ç°éå¸¸ä¼˜ç§€ä¸”ç¨³å¥ï¼Œå…·å¤‡æå¼ºçš„å®æˆ˜ä»·å€¼ï¼Œå¯çº³å…¥æ ¸å¿ƒå¤šå› å­æ¨¡å‹ã€‚"
        elif weighted_score >= 50:
            final_grade = "B (å€¼å¾—å…³æ³¨(50%-70%å¾—åˆ†ç‡))"
            conclusion = "å› å­è¡¨ç°è‰¯å¥½ï¼Œé€šè¿‡äº†å…³é”®è€ƒéªŒï¼Œå…·å¤‡ä¸€å®šAlphaèƒ½åŠ›ï¼Œå¯çº³å…¥å¤‡é€‰æ± æŒç»­è·Ÿè¸ªã€‚"
        elif weighted_score >= 35:
            final_grade = "C (35%çš„å¾—åˆ†ç‡ï¼Œå®åœ¨èµ°æŠ•æ— è·¯äº†ï¼Œåªæœ‰çœ‹çœ‹è¿™ç±»åƒåœ¾äº†)"
            conclusion = "35%çš„å¾—åˆ†ç‡ï¼Œå®åœ¨èµ°æŠ•æ— è·¯äº†ï¼Œåªæœ‰çœ‹çœ‹è¿™ç±»åƒåœ¾äº†-åªæœ‰35%~50%çš„å¾—åˆ†ç‡"
        elif weighted_score >= 20:
            final_grade = "D (å¾ˆå·®å¾ˆå·®-åªæœ‰20%~35%çš„å¾—åˆ†ç‡)"
            conclusion = "å¾ˆå·®å¾ˆå·®åªæœ‰20%~35%çš„å¾—åˆ†ç‡"
        else:
            final_grade = "E (å»ºè®®ä¼˜åŒ–)"
            conclusion = "å› å­è¡¨ç°å®åœ¨å¹³åº¸ï¼Œå»ºè®®ä¼˜åŒ–æˆ–ä»…ä½œä¸ºåˆ†æ•£åŒ–è¡¥å……ã€‚ï¼ˆ20%çš„å¾—åˆ†ç‡éƒ½æ²¡æœ‰ï¼‰"

        return {
            'final_grade': final_grade,
            'final_score': f"{weighted_score:.1f}/100",
            'conclusion': conclusion,

            'sub': {
                'IC': {"grade": score_ic_eval.get('grade'), n_metrics_pass_rate_key: ic_n_metrics_pass_rate},
                'Quantile': {"grade": quantile_grade, n_metrics_pass_rate_key: quantile_n_metrics_pass_rate},
                'Fama-MacBeth': {"grade": fm_grade, n_metrics_pass_rate_key: fm_n_metrics_pass_rate}
            }
        }

    # ok å› ä¸ºéœ€è¦æ»šåŠ¨è®¡ç®—ï¼Œæ‰€ä»¥ä¸ä¾èµ–è‚¡ç¥¨æ± çš„indexï¼ˆtradeï¼‰ åªè¦å¯¹é½è‚¡ç¥¨åˆ—å°±å¥½
    def get_pct_chg_beta_dict(self):
        dict = {}
        for pool_name, _ in self.stock_pools_dict.items():
            beta_df = self.get_pct_chg_beta_data_for_pool(pool_name)
            dict[pool_name] = beta_df
        return dict

    # ok ok æ³¨æ„ ç”¨çš„æ—¶å€™åˆ«å¿˜äº†shiftï¼ˆ1ï¼‰

    def check_shape(self):
        pool_names = self.stock_pools_dict.keys()
        pool_shape_config = {}
        for pool_name in pool_names:
            pool_shape_config[pool_name] = self.stock_pools_dict[pool_name].shape

        for pool_name, shape in pool_shape_config.items():
            if shape != self.factor_manager.close_df_diff_stock_pools_dict[pool_name].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
            if shape != self.factor_manager.circ_mv__shift_diff_stock_pools_dict[pool_name].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
            if shape != self.factor_manager.pct_chg_beta_shift_diff_stock_pools_dict[pool_name].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")

            if shape != self.factor_manager.auxiliary_dfs_shift_diff_stock_polls_dict[pool_name]['pct_chg_beta'].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
            if shape != self.factor_manager.auxiliary_dfs_shift_diff_stock_polls_dict[pool_name]['industry'].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
            if shape != self.factor_manager.auxiliary_dfs_shift_diff_stock_polls_dict[pool_name]['total_mv'].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
            #  å› ä¸º_prepare_for_neutral_data  å…¥å‚çš„df ç¬¬ä¸€è¡Œæ˜¯NANï¼ˆshiftå¯¼è‡´ï¼‰ç»è¿‡industry_stacked_series = industry_df.stack().dropna() ï¼Œæœ€åä¼šå°‘ä¸€è¡Œï¼Œå¾ˆæ­£å¸¸ï¼æ‰€ä»¥æš‚ä¸”ä¸åˆ¤æ–­è¿™ä¸ªé•¿åº¦
            # if shape != self.prepare_for_neutral_dfs_shift_diff_stock_pools_dict[pool_name]['industry_å†œä¸šç»¼åˆ'].shape:
            #     raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")

            if shape != self.factor_manager.prepare_for_neutral_dfs_shift_diff_stock_pools_dict[pool_name][
                'total_mv'].shape:
                raise ValueError("å½¢çŠ¶ä¸ä¸€è‡´ ï¼Œè¯·å¿…é¡»æ£€æŸ¥")
    # #åˆæˆæµ‹è¯•ï¼Œå•å› å­æµ‹è¯•
    # def test_factor_entity_service_route(self,
    #                                factor_name: str,
    #                                stock_pool_name: str,
    #                                preprocess_method: str = "standard",
    #                                ) -> Dict[str, Any]:
    #     """
    #     æµ‹è¯•å•ä¸ªå› å­
    #     ç»¼åˆè¯„åˆ†
    #     ä¿å­˜ç»“æœ
    #     ç”»å›¾ä¿å­˜
    #     """
    #     factor_data_shifted,is_composite_factor,start_date, end_date, stock_pool_index_code, stock_pool_name, style_category, test_configurations\
    #         = self.prepare_date_for_entity_service(
    #         factor_name,stock_pool_name)
    #     all_configs_results = {}
    #     if is_composite_factor:
    #        return  self.test_factor_entity_service_for_composite_factor(factor_name, factor_data_shifted,stock_pool_name, test_configurations, start_date, end_date, stock_pool_index_code)
    #     for calculator_name, func in test_configurations.items():
    #         # # æ‰§è¡Œæµ‹è¯•
    #         # # log_flow_start(f"å› å­{factor_name}åŸå§‹çŠ¶æ€ è¿›å…¥comprehensive_testæµ‹è¯• ")
    #         # raw_factor_df, ic_s_raw, ic_st_raw, q_r_raw, q_daily_returns_df_raw,q_st_raw, _, _, _, _, _ = self.comprehensive_test(
    #         #     target_factor_name=factor_name,
    #         #     factor_data_shifted =factor_data_shifted,
    #         #     stock_pool_name=stock_pool_name,
    #         #     returns_calculator=func,
    #         #     preprocess_method="standard",
    #         #     start_date=start_date,
    #         #     end_date=end_date,
    #         #     need_process_factor=False,
    #         #     do_ic_test=True, do_quantile_test=True, do_turnover_test=False, do_fama_test=False, #do_style_correlation_test do_fama_test do_turnover_test å†æœªç»è¿‡é¢„æµ‹é‡Œçš„æ•°æ®ä¸Šæµ‹è¯•æ²¡æœ‰æ„ä¹‰! æ‰€ä»¥ç½®ä¸ºfalse
    #         #     do_style_correlation_test=False
    #         # )
    #         # log_flow_start(f"å› å­{factor_name}å¤„ç†çŠ¶æ€ è¿›å…¥comprehensive_testæµ‹è¯• ")
    #         proceessed_df, ic_s, ic_st, q_r_processed, q_daily_returns_df_proc, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict \
    #             = self.comprehensive_test(
    #             target_factor_name=factor_name,
    #             factor_data_shifted=factor_data_shifted,
    #             stock_pool_name = stock_pool_name,
    #             returns_calculator=func,
    #             preprocess_method="standard",
    #             start_date=start_date,
    #             end_date=end_date,
    #             need_process_factor=True,
    #             do_ic_test=True, do_turnover_test=True, do_quantile_test=True, do_fama_test=True,
    #             do_style_correlation_test=True
    #         )
    #         single_config_results = {
    #             "raw_factor_df": None, #æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
    #             "processed_factor_df": proceessed_df,#æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
    #             "ic_series_periods_dict_raw": None,
    #             "ic_stats_periods_dict_raw": None,
    #             "ic_series_periods_dict_processed": ic_s,
    #             "ic_stats_periods_dict_processed": ic_st,
    #
    #             "quantile_returns_series_periods_dict_raw": None,
    #             "quantile_stats_periods_dict_raw": None,
    #             "q_daily_returns_df_raw": None,
    #
    #             "quantile_returns_series_periods_dict_processed": q_r_processed,
    #             "quantile_stats_periods_dict_processed": q_st,
    #             "q_daily_returns_df_processed": q_daily_returns_df_proc,
    #
    #             "fm_returns_series_periods_dict": fm_returns_series_dict,
    #             "fm_stat_results_periods_dict": fm_summary_dict,
    #             "turnover_stats_periods_dict": turnover,
    #             "style_correlation_dict": style_correlation_dict
    #         }
    #         # b) å°†æœ¬æ¬¡é…ç½®çš„æ‰€æœ‰ç»“æœæ‰“åŒ…
    #         self.factorResultsManager._save_factor_results(  # å‡è®¾ä¿å­˜å‡½æ•°åœ¨FactorManagerä¸­
    #             factor_name=factor_name,
    #             stock_index=stock_pool_index_code,
    #             start_date=start_date,
    #             end_date=end_date,
    #             returns_calculator_func_name=calculator_name,
    #             results=single_config_results
    #         )
    #         all_configs_results[calculator_name] = single_config_results
    #     # overrall_summary_stats = self.landing_for_core_three_analyzer_result(target_factor_df, target_factor_name,
    #     #                                                                      style_category, "standard",
    #     #                                                                      ic_s, ic_st, q_r_processed, q_st, fm_r, fm_st, turnover_st, style_corr
    #     #                                                                      )
    #     return all_configs_results

    # åˆæˆæµ‹è¯•ï¼Œå•å› å­æµ‹è¯•
    def test_factor_entity_service_route(self,
                                         factor_name: str,
                                         stock_pool_index_name: str,
                                         preprocess_method: str = "standard",
                                         ) -> Dict[str, Any]:
        """
        æµ‹è¯•å•ä¸ªå› å­
        ç»¼åˆè¯„åˆ†
        ä¿å­˜ç»“æœ
        ç”»å›¾ä¿å­˜
        """
        factor_data_shifted, is_composite_factor, start_date, end_date, stock_pool_index_code, stock_pool_name, style_category, test_configurations \
            = self.prepare_date_for_entity_service(
            factor_name, stock_pool_index_name)

        # è·å–eva_dataé…ç½®ï¼Œé»˜è®¤æµ‹è¯•ä¸¤ç§æ•°æ®çŠ¶æ€
        eva_data_config = self.config.get('evaluation', {}).get('eva_data', ['raw', 'processed'])

        all_configs_results = {}
        if is_composite_factor:
            return self.test_factor_entity_service_for_composite_factor(factor_name, factor_data_shifted,
                                                                        stock_pool_index_name, test_configurations,
                                                                        start_date, end_date, stock_pool_index_code)
        
        for calculator_name, func in test_configurations.items():
            single_config_results = {}
            
            # åˆå§‹åŒ–å˜é‡ä¸ºNone
            raw_factor_df = ic_s_raw = ic_st_raw = q_r_raw = q_daily_returns_df_raw = q_st_raw = None
            proceessed_df = ic_s = ic_st = q_r_processed = q_daily_returns_df_proc = q_st = turnover = fm_returns_series_dict = fm_t_stats_series_dict = fm_summary_dict = style_correlation_dict = None
            
            # æ ¹æ®é…ç½®å†³å®šæ‰§è¡Œå“ªäº›æµ‹è¯•
            if 'raw' in eva_data_config:
                logger.info(f"ğŸ”„ æ‰§è¡ŒåŸå§‹å› å­æµ‹è¯•: {factor_name}")
                raw_factor_df, ic_s_raw, ic_st_raw, q_r_raw, q_daily_returns_df_raw, q_st_raw, _, _, _, _, _ = self.comprehensive_test(
                    target_factor_name=factor_name,
                    factor_data_shifted=factor_data_shifted,
                    stock_pool_index_name=stock_pool_index_name,
                    returns_calculator=func,
                    preprocess_method="standard",
                    start_date=start_date,
                    end_date=end_date,
                    need_process_factor=False,
                    do_ic_test=True, do_quantile_test=True, do_turnover_test=False, do_fama_test=False,
                    # do_style_correlation_test do_fama_test do_turnover_test å†æœªç»è¿‡é¢„æµ‹é‡Œçš„æ•°æ®ä¸Šæµ‹è¯•æ²¡æœ‰æ„ä¹‰! æ‰€ä»¥ç½®ä¸ºfalse
                    do_style_correlation_test=False
                )
                
            if 'processed' in eva_data_config:
                logger.info(f"âš™ï¸ æ‰§è¡Œå¤„ç†åå› å­æµ‹è¯•: {factor_name}")
                proceessed_df, ic_s, ic_st, q_r_processed, q_daily_returns_df_proc, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict \
                    = self.comprehensive_test(
                    target_factor_name=factor_name,
                    factor_data_shifted=factor_data_shifted,
                    stock_pool_index_name=stock_pool_index_name,
                    returns_calculator=func,
                    preprocess_method="standard",
                    start_date=start_date,
                    end_date=end_date,
                    need_process_factor=True,
                    do_ic_test=True, do_turnover_test=True, do_quantile_test=True, do_fama_test=True,
                    do_style_correlation_test=True
                )
            
            # æ„å»ºç»“æœå­—å…¸
            single_config_results = {
                "raw_factor_df": raw_factor_df,  # æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
                "processed_factor_df": proceessed_df,  # æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
                "ic_series_periods_dict_raw": ic_s_raw,
                "ic_stats_periods_dict_raw": ic_st_raw,
                "ic_series_periods_dict_processed": ic_s,
                "ic_stats_periods_dict_processed": ic_st,

                "quantile_returns_series_periods_dict_raw": q_r_raw,
                "quantile_stats_periods_dict_raw": q_st_raw,
                "q_daily_returns_df_raw": q_daily_returns_df_raw,

                "quantile_returns_series_periods_dict_processed": q_r_processed,
                "quantile_stats_periods_dict_processed": q_st,
                "q_daily_returns_df_processed": q_daily_returns_df_proc,

                "fm_returns_series_periods_dict": fm_returns_series_dict,
                "fm_stat_results_periods_dict": fm_summary_dict,
                "turnover_stats_periods_dict": turnover,
                "style_correlation_dict": style_correlation_dict
            }
            
            # b) å°†æœ¬æ¬¡é…ç½®çš„æ‰€æœ‰ç»“æœæ‰“åŒ…
            self.factorResultsManager._save_factor_results(  # å‡è®¾ä¿å­˜å‡½æ•°åœ¨FactorManagerä¸­
                factor_name=factor_name,
                stock_index=stock_pool_index_code,
                start_date=start_date,
                end_date=end_date,
                returns_calculator_func_name=calculator_name,
                results=single_config_results
            )
            all_configs_results[calculator_name] = single_config_results
        return all_configs_results
        # åˆæˆæµ‹è¯•ï¼Œå•å› å­æµ‹è¯•
    # def test_factor_entity_service_route(self,
    #                                      factor_name: str,
    #                                      stock_pool_name: str,
    #                                      preprocess_method: str = "standard",
    #                                      ) -> Dict[str, Any]:
    #     """
    #     æµ‹è¯•å•ä¸ªå› å­
    #     ç»¼åˆè¯„åˆ†
    #     ä¿å­˜ç»“æœ
    #     ç”»å›¾ä¿å­˜
    #     """
    #     factor_data_shifted, is_composite_factor, start_date, end_date, stock_pool_index_code, stock_pool_name, style_category, test_configurations \
    #         = self.prepare_date_for_entity_service(
    #         factor_name, stock_pool_name)
    #
    #     all_configs_results = {}
    #     if is_composite_factor:
    #         return self.test_factor_entity_service_for_composite_factor(factor_name, factor_data_shifted,
    #                                                                     stock_pool_name, test_configurations,
    #                                                                     start_date, end_date, stock_pool_index_code)
    #     for calculator_name, func in test_configurations.items():
    #         # # æ‰§è¡Œæµ‹è¯•
    #         # # log_flow_start(f"å› å­{factor_name}åŸå§‹çŠ¶æ€ è¿›å…¥comprehensive_testæµ‹è¯• ")
    #         # raw_factor_df, ic_s_raw, ic_st_raw, q_r_raw, q_daily_returns_df_raw, q_st_raw, _, _, _, _, _ = self.comprehensive_test(
    #         #     target_factor_name=factor_name,
    #         #     factor_data_shifted=factor_data_shifted,
    #         #     stock_pool_name=stock_pool_name,
    #         #     returns_calculator=func,
    #         #     preprocess_method="standard",
    #         #     start_date=start_date,
    #         #     end_date=end_date,
    #         #     need_process_factor=False,
    #         #     do_ic_test=True, do_quantile_test=True, do_turnover_test=False, do_fama_test=False,
    #         #     # do_style_correlation_test do_fama_test do_turnover_test å†æœªç»è¿‡é¢„æµ‹é‡Œçš„æ•°æ®ä¸Šæµ‹è¯•æ²¡æœ‰æ„ä¹‰! æ‰€ä»¥ç½®ä¸ºfalse
    #         #     do_style_correlation_test=False
    #         # )
    #         # log_flow_start(f"å› å­{factor_name}å¤„ç†çŠ¶æ€ è¿›å…¥comprehensive_testæµ‹è¯• ")
    #         proceessed_df, ic_s, ic_st, q_r_processed, q_daily_returns_df_proc, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict \
    #             = self.comprehensive_test(
    #             target_factor_name=factor_name,
    #             factor_data_shifted=factor_data_shifted,
    #             stock_pool_name=stock_pool_name,
    #             returns_calculator=func,
    #             preprocess_method="standard",
    #             start_date=start_date,
    #             end_date=end_date,
    #             need_process_factor=True,
    #             do_ic_test=True, do_turnover_test=True, do_quantile_test=True, do_fama_test=True,
    #             do_style_correlation_test=True
    #         )
    #         single_config_results = {
    #             "raw_factor_df": None,  # æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
    #             "processed_factor_df": proceessed_df,  # æ³¨æ„ éƒ½æ˜¯ç»è¿‡shift1çš„
    #             "ic_series_periods_dict_raw": None,
    #             "ic_stats_periods_dict_raw": None,
    #             "ic_series_periods_dict_processed": ic_s,
    #             "ic_stats_periods_dict_processed": ic_st,
    #
    #             "quantile_returns_series_periods_dict_raw": None,
    #             "quantile_stats_periods_dict_raw": None,
    #             "q_daily_returns_df_raw": None,
    #
    #             "quantile_returns_series_periods_dict_processed": q_r_processed,
    #             "quantile_stats_periods_dict_processed": q_st,
    #             "q_daily_returns_df_processed": q_daily_returns_df_proc,
    #
    #             "fm_returns_series_periods_dict": fm_returns_series_dict,
    #             "fm_stat_results_periods_dict": fm_summary_dict,
    #             "turnover_stats_periods_dict": turnover,
    #             "style_correlation_dict": style_correlation_dict
    #         }
    #         # b) å°†æœ¬æ¬¡é…ç½®çš„æ‰€æœ‰ç»“æœæ‰“åŒ…
    #         self.factorResultsManager._save_factor_results(  # å‡è®¾ä¿å­˜å‡½æ•°åœ¨FactorManagerä¸­
    #             factor_name=factor_name,
    #             stock_index=stock_pool_index_code,
    #             start_date=start_date,
    #             end_date=end_date,
    #             returns_calculator_func_name=calculator_name,
    #             results=single_config_results
    #         )
    #         all_configs_results[calculator_name] = single_config_results
    #     # overrall_summary_stats = self.landing_for_core_three_analyzer_result(target_factor_df, target_factor_name,
    #     #                                                                      style_category, "standard",
    #     #                                                                      ic_s, ic_st, q_r_processed, q_st, fm_r, fm_st, turnover_st, style_corr
    #     #                                                                      )
    #     return all_configs_results
    def purify_summary_rows_contain_periods(self, comprehensive_results):
        factor_category = comprehensive_results.get('factor_category', 'Unknown')  # ä½¿ç”¨.getå¢åŠ å¥å£®æ€§
        factor_name = comprehensive_results['factor_name']

        ic_stats_periods_dict = comprehensive_results['ic_analysis']
        quantile_stats_periods_dict = comprehensive_results['quantile_backtest']
        fm_stat_results_periods_dict = comprehensive_results['fama_macbeth']

        # ä»¥ ic_stats çš„ keys ä¸ºå‡†ï¼Œç¡®ä¿æ‰€æœ‰å­—å…¸éƒ½æœ‰è¿™äº›å‘¨æœŸ
        periods = ic_stats_periods_dict.keys()
        purify_summary_rows = []

        for period in periods:
            # åœ¨å¾ªç¯å†…éƒ¨è¿›è¡Œé˜²å¾¡æ€§æ£€æŸ¥ï¼Œç¡®ä¿æ‰€æœ‰ç»“æœå­—å…¸éƒ½åŒ…å«å½“å‰å‘¨æœŸ
            if not all(period in d for d in [quantile_stats_periods_dict, fm_stat_results_periods_dict]):
                print(f"è­¦å‘Šï¼šå› å­ {factor_name} åœ¨å‘¨æœŸ {period} çš„ç»“æœä¸å®Œæ•´ï¼Œå·²è·³è¿‡ã€‚")
                continue

            summary_row = {
                'factor_name': factor_name,
                'test_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'factor_category': factor_category,
                'backtest_period': self.backtest_period,
                'backtest_base_on_index': comprehensive_results['backtest_base_on_index'],

                'period': period,  # ã€BUGå·²ä¿®æ­£ã€‘è¿™é‡Œåº”è¯¥æ˜¯å•ä¸ªå‘¨æœŸ
                # æ”¶ç›Šç»´åº¦
                'tmb_sharpe': quantile_stats_periods_dict[period]['tmb_sharpe'],
                'tmb_annual_return': quantile_stats_periods_dict[period]['tmb_annual_return'],
                # é£é™©ä¸ç¨³å®šæ€§ç»´åº¦ (Risk & Stability Dimension) - è¿‡ç¨‹æœ‰å¤šé¢ ç°¸
                'tmb_max_drawdown': quantile_stats_periods_dict[period]['max_drawdown'],
                'ic_ir': ic_stats_periods_dict[period]['ic_ir'],
                # çº¯å‡€åº¦ä¸ç‹¬ç‰¹æ€§ç»´åº¦ (Purity & Uniqueness Dimension) - â€œæ˜¯çœŸAlphaè¿˜æ˜¯åªæ˜¯é£é™©æš´éœ²
                'fm_t_statistic': fm_stat_results_periods_dict[period]['t_statistic'],
                'monotonicity_spearman': quantile_stats_periods_dict[period]['monotonicity_spearman'],
                'ic_mean': ic_stats_periods_dict[period]['ic_mean']
            }
            # score = calculate_factor_score(summary_row)
            # summary_row['score'] = score
            purify_summary_rows.append(summary_row)
        return purify_summary_rows

    def build_fm_return_series_dict(self, fm_factor_returns_series_periods_dict, target_factor_name):
        fm_factor_returns = {}

        for period, return_series in fm_factor_returns_series_periods_dict.items():
            colum_name = f'{target_factor_name}_{period}'
            fm_factor_returns[colum_name] = return_series

        return fm_factor_returns
    #
    # def batch_test_factors(self,
    #                        target_factors_dict: Dict[str, pd.DataFrame],
    #                        **test_kwargs) :
    #     """
    #     æ‰¹é‡æµ‹è¯•å› å­
    #     """
    #
    #     # æ‰¹é‡æµ‹è¯•
    #     results = []
    #     for factor_name, factor_data in target_factors_dict.items():
    #         try:
    #             # æ‰§è¡Œæµ‹è¯•
    #             results.append( {factor_name:(self.test_factor_entity_service(
    #                 factor_name=factor_name,
    #                 factor_df=factor_data,
    #                 need_process_factor=True,
    #                 is_composite_factor=False,
    #             ))})
    #         except Exception as e:
    #             raise ValueError(f"âœ— å› å­{factor_name}æµ‹è¯•å¤±è´¥: {e}") from e
    #
    #     return results

    def core_three_test(self, factor_df, target_factor_name,
                        returns_calculator: Callable[[int, pd.DataFrame, pd.DataFrame], pd.DataFrame],
                        close_df,
                        prepare_for_neutral_shift_base_own_stock_pools_dfs, circ_mv_shift_df, style_factors_dict,
                        do_ic_test, do_turnover_test, do_quantile_test, do_fama_test, do_style_correlation_test
                        ) -> tuple[
        dict[str, Series] | None, dict[str, DataFrame] | None, dict[str, DataFrame] | None, DataFrame | None,pd.DataFrame | None,
        dict[Any, Any] | None, dict[str, DataFrame] | None, dict[str, DataFrame] | None, dict[str, DataFrame] | None,
        dict[str, float] | None]:

        # 1. ICå€¼åˆ†æ
        logger.info("\t2. æ­£å¼æµ‹è¯• ä¹‹ ICå€¼åˆ†æ...")
        ic_s = ic_st = q_r = q_st = turnover = fm_returns_series_dict = fm_t_stats_series_dict = fm_summary_dict = style_correlation_dict = None
        if do_ic_test:
            ic_s, ic_st = self.test_ic_analysis(factor_df,
                                                returns_calculator, close_df,
                                                target_factor_name)
        # 2. åˆ†å±‚å›æµ‹
        logger.info("\t3.  æ­£å¼æµ‹è¯• ä¹‹ åˆ†å±‚å›æµ‹...")
        if do_quantile_test:
            # è¿™æ˜¯ä¸­æ€§åŒ–ä¹‹åçš„åˆ†ç»„æ”¶ç›Šï¼Œä¹Ÿå°±æ˜¯çº¯å‡€çš„å•çº¯å› å­è‡ªå·±å¸¦æ¥çš„æ”¶ç›Šã€‚è‡³äºåœ¨çœŸå®çš„å¸‚åœºä¸Šï¼Œç¦ä¸ç¦å¾—èµ·è€ƒéªŒï¼Œè¿™ä¸ªæ— æ³•çœ‹å‡ºã€‚éœ€è¦åœ¨åŸå§‹å› å­ï¼ˆæœªé™¤æ‚/ä¸­æ€§åŒ–ï¼‰ï¼Œç„¶ååˆ†ç»„æŸ¥çœ‹æ”¶ç›Šæ‰è¡Œï¼
            q_r, q_st = self.test_quantile_backtest(
                factor_df, returns_calculator, close_df, target_factor_name)

        if do_turnover_test:
            turnover = self.test_turnover_result(factor_df)

        q_daily_returns_df = calculate_quantile_daily_returns(factor_df,returns_calculator,  5
                                                                                )
        # 3. Fama-MacBethå›å½’
        if do_fama_test:
            logger.info("\t4.  æ­£å¼æµ‹è¯• ä¹‹ Fama-MacBethå›å½’...")
            fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict = fama_macbeth(
                factor_data=factor_df, returns_calculator=returns_calculator, close_df=close_df,
                forward_periods=self.test_common_periods,
                neutral_dfs={},#å› ä¸ºå› å­é¢„å¤„ç† processer é˜¶æ®µï¼Œä»¥ç»å¯¹å› å­è¿›è¡Œäº† ä¸­æ€§åŒ–è¡Œä¸šã€æå€¼ã€betaå¤„ç† ï¼Œæ‰€ä»¥è¿™é‡Œä¼ ç©º ä¸å†å¤„ç†
                circ_mv_df_shifted=circ_mv_shift_df,
                factor_name=target_factor_name)

        # ã€æ–°å¢ã€‘4. é£æ ¼ç›¸å…³æ€§åˆ†æ
        logger.info("\t5.  æ­£å¼æµ‹è¯• ä¹‹ é£æ ¼ç›¸å…³æ€§åˆ†æ...")
        if do_style_correlation_test:
            style_correlation_dict = self.test_style_correlation(
                factor_df,
                style_factors_dict
            )
        return ic_s, ic_st, q_r,q_daily_returns_df, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict
#åºŸå¼ƒ
    # def landing_for_core_three_analyzer_result(self, target_factor_df, target_factor_name, category, preprocess_method,
    #                                            ic_series_periods_dict, ic_stats_periods_dict,
    #                                            quantile_daily_returns_for_plot_dict, quantile_stats_periods_dict,
    #                                            factor_returns_series_periods_dict, fm_stat_results_periods_dict,
    #                                            turnover_stats_periods_dict, style_correlation_dict):
    #     #  ç»¼åˆè¯„ä»·
    #     evaluation_score_dict = self.evaluation_score_dict(ic_stats_periods_dict,
    #                                                        quantile_stats_periods_dict,
    #                                                        fm_stat_results_periods_dict)
    #     # æ•´åˆç»“æœ
    #     comprehensive_results = {
    #         'factor_name': target_factor_name,
    #         'factor_category': category,
    #         # 'backtest_base_on_index': self.factor_manager.get_stock_pool_index_by_factor_name(target_factor_name),
    #         'backtest_period': self.backtest_period,
    #         'test_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    #         'preprocess_method': preprocess_method,
    #         'ic_analysis': ic_stats_periods_dict,
    #         'quantile_backtest': quantile_stats_periods_dict,
    #         'fama_macbeth': fm_stat_results_periods_dict,
    #         'evaluate_factor_score': evaluation_score_dict
    #     }
    #     overrall_summary_stats = self.overrall_summary(comprehensive_results)
    #     purify_summary_rows_contain_periods = self.purify_summary_rows_contain_periods(comprehensive_results)
    #     fm_return_series_dict = self.build_fm_return_series_dict(factor_returns_series_periods_dict, target_factor_name)
    #
    #     self.factor_manager._save_results(overrall_summary_stats, file_name_prefix='overrall_summary')
    #     self.factor_manager.update_and_save_factor_purify_summary(purify_summary_rows_contain_periods,
    #                                                               file_name_prefix='purify_summary')
    #     self.factor_manager.update_and_save_fm_factor_return_matrix(fm_return_series_dict,
    #                                                                 file_name_prefix='fm_return_series')
    #     # ç”»å›¾ä¿å­˜
    #     all_periods = ic_stats_periods_dict.keys()
    #     # åœ¨æ‰€æœ‰è®¡ç®—ç»“æŸåï¼Œåªè°ƒç”¨ä¸€æ¬¡ç»Ÿä¸€æŠ¥å‘Šå‡½æ•°
    #     self.visualizationManager.plot_unified_factor_report(
    #         backtest_base_on_index=comprehensive_results['backtest_base_on_index'],
    #         factor_name=target_factor_name,
    #         ic_series_periods_dict=ic_series_periods_dict,
    #         ic_stats_periods_dict=ic_stats_periods_dict,
    #         quantile_returns_series_periods_dict=quantile_daily_returns_for_plot_dict,
    #         quantile_stats_periods_dict=quantile_stats_periods_dict,
    #         factor_returns_series_periods_dict=factor_returns_series_periods_dict,
    #         fm_stat_results_periods_dict=fm_stat_results_periods_dict,
    #         turnover_stats_periods_dict=turnover_stats_periods_dict,
    #         style_correlation_dict=style_correlation_dict,
    #         factor_df=target_factor_df  # ä¼ å…¥æœªç»shiftçš„Tæ—¥å› å­
    #     )
    #
    #     return overrall_summary_stats

    def get_style_factors(self, stock_pool_name: str) -> Dict[str, pd.DataFrame]:
        """è·å–å¸¸è§çš„é£æ ¼å› å­, å¹¶ä¸è‚¡ç¥¨æ± å¯¹é½"""
        style_factors = {}

        # for factor_name in ['total_mv', 'pb', 'ps_ttm', 'roe_ttm', 'momentum_21d']:#å†™æ­»ï¼Ÿ è¿˜æœ‰åˆ«çš„å— todo
        ##
        # é£æ ¼å› å­ (Style Factor) = å¸‚åœºä¸Šå…¬è®¤çš„ã€èƒ½é•¿æœŸè§£é‡Šè‚¡ç¥¨æ”¶ç›Šå·®å¼‚çš„å‡ ç±»å› å­ã€‚æœ€è‘—åçš„å¦‚ï¼š
        #
        # è§„æ¨¡ (Size): å¸‚å€¼å¤§å°ã€‚é€šå¸¸ç”¨æ€»å¸‚å€¼æˆ–æµé€šå¸‚å€¼çš„å¯¹æ•°è¡¨ç¤ºã€‚
        #
        # ä»·å€¼ (Value): ä¼°å€¼é«˜ä½ã€‚å¦‚å¸‚ç›ˆç‡PEã€å¸‚å‡€ç‡PBã€‚
        #
        # åŠ¨é‡ (Momentum): è¿‘æœŸæ¶¨è·Œè¶‹åŠ¿ã€‚å¦‚è¿‡å»Nå¤©çš„æ”¶ç›Šç‡ã€‚
        #
        # è´¨é‡ (Quality): å…¬å¸è´¨åœ°ã€‚å¦‚å‡€èµ„äº§æ”¶ç›Šç‡ROEã€‚
        #
        # æ³¢åŠ¨ç‡ (Volatility): è‚¡ä»·æ³¢åŠ¨æ€§ã€‚å¦‚è¿‡å»Nå¤©çš„å¹´åŒ–æ³¢åŠ¨ç‡ã€‚
        #
        # çœŸå®æ•°æ®æ¡ˆä¾‹ï¼š å‡è®¾ä½ å‘æ˜äº†ä¸€ä¸ªâ€œåˆ†æå¸ˆä¸Šè°ƒè¯„çº§æ¬¡æ•°â€å› å­ï¼Œå›æµ‹å‘ç°æ•ˆæœå¾ˆå¥½ã€‚ä½†å¦‚æœä½ è®¡ç®—å®ƒå’Œè§„æ¨¡å› å­çš„ç›¸å…³æ€§ï¼Œå‘ç°é«˜è¾¾0.6ã€‚è¿™è¯´æ˜åˆ†æå¸ˆæ›´å€¾å‘äºè¦†ç›–å’Œè¯„çº§å¤§å¸‚å€¼çš„å…¬å¸ã€‚é‚£ä¹ˆä½ çš„å› å­æ”¶ç›Šï¼Œå¾ˆå¤§ä¸€éƒ¨åˆ†å…¶å®åªæ˜¯æ­äº†â€œå¤§ç›˜è‚¡æ•ˆåº”â€çš„ä¾¿è½¦ï¼Œå¹¶éçœŸæ­£ç‹¬ç‰¹çš„Alphaã€‚å½“å¸‚åœºé£æ ¼ä»å¤§ç›˜åˆ‡æ¢åˆ°å°ç›˜æ—¶ï¼Œä½ çš„å› å­å¯èƒ½ä¼šçªç„¶å¤±æ•ˆã€‚#
        style_factor_list = self.factor_manager.data_manager.config['evaluation']['style_factor_list']
        # style_factor_list = [
        #     # è§„æ¨¡å› å­ (å¿…é¡»å¯¹æ•°åŒ–)
        #     'log_circ_mv',
        #     # ä»·å€¼å› å­ (å»ºè®®ç”¨å€’æ•°)
        #     'bm_ratio', 'sp_ratio', 'ep_ratio',
        #     # æˆé•¿å› å­
        #     'net_profit_growth_ttm',
        #     'revenue_growth_ttm',
        #     # è´¨é‡å› å­
        #     'roe_ttm',
        #     'gross_margin_ttm',
        #     # é£é™©/æ³¢åŠ¨å› å­
        #     'volatility_90d',
        #     'beta',
        #     # åŠ¨é‡/åè½¬å› å­
        #     'reversal_21d',  # Aè‚¡å¸¸ç”¨çŸ­æœŸåè½¬
        #     # æµåŠ¨æ€§å› å­
        #     'ln_turnover_value_90d'
        # ]
        for factor_name in style_factor_list:
            #   build_df_dict... å‡½æ•°å¯ä»¥è·å–å› å­æ•°æ®å¹¶åº”ç”¨T-1åŸåˆ™

            df = self.factor_manager.get_prepare_aligned_factor_for_analysis(
                factor_request=factor_name,
                stock_pool_index_name=stock_pool_name,for_test=True)


            style_factors[factor_name] = df
        return style_factors

    def test_style_correlation(self,
                               factor_data: pd.DataFrame,
                               style_factors_dict: Dict[str, pd.DataFrame]
                               ) -> Dict[str, float]:
        """
        ã€æ–°å¢ã€‘æµ‹è¯•ç›®æ ‡å› å­ä¸ä¸€ç»„é£æ ¼å› å­çš„æˆªé¢ç›¸å…³æ€§ã€‚
        """
        logger.info("    > æ­£åœ¨è®¡ç®—ä¸å¸¸è§é£æ ¼å› å­çš„ç›¸å…³æ€§...")
        correlation_results = {}

        for style_name, style_df in style_factors_dict.items():
            # å¯¹é½æ•°æ®
            factor_aligned, style_aligned = factor_data.align(style_df, join='inner', axis=None)

            if factor_aligned.empty:
                correlation_results[style_name] = np.nan
                continue

            # é€æ—¥è®¡ç®—æˆªé¢ç›¸å…³æ€§
            daily_corr = factor_aligned.corrwith(style_aligned, axis=1, method='spearman')

            # å­˜å‚¨å¹³å‡ç›¸å…³æ€§
            correlation_results[f'corr_with_{style_name}'] = daily_corr.mean()

        return correlation_results
    #ç”Ÿæˆt-1çš„æ•°æ® ç”¨äºå› å­é¢„å¤„ç†
    def prepare_date_for_process_factor(self, target_factor_name, trade_dates,stock_codes,stock_pool_name):
        # ç›®æ ‡å› å­åŸºç¡€ä¿¡æ¯å‡†å¤‡
        style_category = self.factor_manager.get_style_category(target_factor_name)

        # 1. ä»é…ç½®ä¸­è¯»å–æ‰€éœ€çš„è¡Œä¸šçº§åˆ«
        neutralization_config = self.factor_processor.preprocessing_config.get('neutralization', {})
        industry_level = neutralization_config.get('by_industry', {}).get('industry_level', 'l1_code')  # é»˜è®¤ä¸ºä¸€çº§è¡Œä¸š

        # 2. åˆå§‹åŒ–PITåœ°å›¾
        # pit_map = PointInTimeIndustryMap()  # å®ƒèƒ½è‡ªåŠ¨åŠ è½½æ•°æ®

        # 3. åŠ¨æ€ç”Ÿæˆæ‰€éœ€çš„è¡Œä¸šå“‘å˜é‡
        industry_dummies_dict = prepare_industry_dummies(
            pit_map=self.factor_manager.data_manager.pit_map,
            trade_dates=trade_dates,
            stock_codes=stock_codes,
            level=industry_level
        )

        BETA_REQUEST = ('beta',  self.factor_manager.data_manager.get_stock_pool_index_code_by_name(stock_pool_name))  #

        # ã€ä¿®æ­£ã€‘get_prepare_aligned_factor_for_analysis ç°åœ¨å·²ç»è¿”å›T-1å€¼
        final_neutral_dfs = {
            # è·å–å·²ç»shiftå¹¶å¯¹é½çš„T-1ä¸­æ€§åŒ–å› å­
            'circ_mv': self.factor_manager.get_prepare_aligned_factor_for_analysis('circ_mv',stock_pool_name,True), #å¤©å‘ä¹‹å‰ç”¨çš„å¯¹æ•°å¸‚å€¼ï¼å¯¼è‡´åˆ†ç»„å•è°ƒç³»æ•°å¼‚å¸¸é«˜ï¼Œå®³æˆ‘æ’æŸ¥å¾ˆä¹… (åˆæ­¥æ€€ç–‘æ˜¯ffillå¯¼è‡´ç ´åäº†æ•°æ®
            'pct_chg_beta': self.factor_manager.get_prepare_aligned_factor_for_analysis(BETA_REQUEST,stock_pool_name,True),
            # è¡Œä¸šå“‘å˜é‡éœ€è¦å•ç‹¬shift
            **{key: df.shift(1, fill_value=0) for key, df in industry_dummies_dict.items()}
        }
        return  final_neutral_dfs, style_category

    def prepare_date_for_core_test(self, target_factor_name,stock_pool_index_name):
        ##
        # ä¸ºä»€ä¹ˆæ˜¯è¦å¡«å……è¿‡çš„ (_filled)ï¼Ÿ
        #
        # ã€‚close_dfè®¡ç®—å‡ºçš„æœªæ¥æ”¶ç›Šç‡çŸ©é˜µï¼Œæ˜¯åç»­æ‰€æœ‰ç»Ÿè®¡æ£€éªŒï¼ˆICã€åˆ†å±‚å›æµ‹ï¼‰çš„**Yå˜é‡**ã€‚
        # å¦‚æœä½¿ç”¨å¸¦NaNçš„close_adjï¼Œä¼šå¯¼è‡´è®¡ç®—å‡ºçš„forward_returnsçŸ©é˜µä¹Ÿå……æ»¡NaNï¼Œä»è€Œå¤§å¹…å‡å°‘æˆ‘ä»¬ç»Ÿè®¡æ£€éªŒçš„æ ·æœ¬é‡ï¼Œé™ä½ç»“æœçš„ç½®ä¿¡åº¦ã€‚#
        # ä»·æ ¼æ•°æ®ï¼šget_prepare_aligned_factor_for_analysisä¼šè‡ªåŠ¨è¯†åˆ«å¹¶ä¿æŒTæ—¥å€¼ #ç¼ºå¤±å¹¶ä¸å¤š
        close_df = self.factor_manager.get_prepare_aligned_factor_for_analysis('close_hfq', stock_pool_index_name, True)#todo è€ƒè™‘ éè¦ fillå— ï¼Œçœ‹çœ‹åŸæ¥çš„ ç¼ºå¤±ç‡é«˜ä¸é«˜

        # ã€ä¿®æ­£ã€‘get_prepare_aligned_factor_for_analysis ç°åœ¨å·²ç»è¿”å›T-1å€¼
        circ_mv_df_shifted = self.factor_manager.get_prepare_aligned_factor_for_analysis('circ_mv', stock_pool_index_name, True)
        style_factor_dfs = self.get_style_factors(stock_pool_index_name)
        return close_df, circ_mv_df_shifted, style_factor_dfs

    def prepare_date_for_entity_service(self, factor_name, stock_pool_name, his_snap_config_id=None):
        """
        ã€ä¸­å¤®æŒ‡æŒ¥éƒ¨æ–¹æ¡ˆã€‘å‡†å¤‡Tæ—¥çš„æ‰€æœ‰åŸææ–™ï¼Œç„¶åç»Ÿä¸€è¿›è¡Œæ—¶é—´ç§»ä½
        """
        # --- æ­¥éª¤ä¸€ï¼šå‡†å¤‡ã€æ‰€æœ‰ã€‘éœ€è¦çš„ã€Tæ—¥ã€‘åŸææ–™ ---

        is_composite_factor ,use_ic_weighting= self.factor_manager.data_manager.is_composite_factor(factor_name)
        stock_pool_index_code = self.factor_manager.data_manager.get_stock_pool_index_code_by_name(stock_pool_name)

        if is_composite_factor:
            factorComposite =  FactorSynthesizer(self.factor_manager,self,self.factor_processor)
            # æ³¨æ„ï¼šåˆæˆå› å­å†…éƒ¨å·²ç»å¤„ç†äº†shifté€»è¾‘ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨
            factor_data_t1 = factorComposite.do_composite_route(factor_name=factor_name,use_ic_weighting=use_ic_weighting, stock_pool_index_name=stock_pool_name, snap_config_id=his_snap_config_id)
        else:
            # a) è·å–å·²ç»å¯¹é½çš„T-1å› å­å€¼ (get_prepare...å‡½æ•°ç°åœ¨å†…éƒ¨å·²ç»shiftå¹¶å¯¹é½)
            factor_data_t1 = self.factor_manager.get_prepare_aligned_factor_for_analysis(factor_name, stock_pool_name, True)

            logger.info(f"â˜…â˜…â˜…ã€æ—¶é—´å¯¹é½ç¡®è®¤ã€‘å› å­ {factor_name} å·²è·å–T-1å€¼å¹¶ä¸è‚¡ç¥¨æ± å¯¹é½ â˜…â˜…â˜…")

        start_date = self.factor_manager.data_manager.config['backtest']['start_date']
        end_date = self.factor_manager.data_manager.config['backtest']['end_date']
        style_category_type = \
            self.factor_manager.data_manager.get_which_field_of_factor_definition_by_factor_name(factor_name,
                                                                                                 'style_category').iloc[
                0]

        # b) è·å–Tæ—¥çš„ä»·æ ¼æ•°æ®ï¼ˆç”¨äºæ”¶ç›Šç‡è®¡ç®—ï¼Œget_prepare_aligned_factor_for_analysisä¼šè‡ªåŠ¨è¯†åˆ«å¹¶ä¿æŒTæ—¥å€¼ï¼‰
        close_df = self.factor_manager.get_prepare_aligned_factor_for_analysis(factor_request='close_hfq', stock_pool_index_name=stock_pool_name, for_test=True)
        open_df = self.factor_manager.get_prepare_aligned_factor_for_analysis(factor_request='open_hfq', stock_pool_index_name=stock_pool_name, for_test=True)

        # å‡†å¤‡æ”¶ç›Šç‡è®¡ç®—å™¨ï¼ˆä»·æ ¼æ•°æ®ä¸éœ€è¦shiftï¼Œå› ä¸ºæˆ‘ä»¬è¦è®¡ç®—Tæ—¥çš„æ”¶ç›Šç‡ï¼‰
        o2o_calculator = partial(calculate_forward_returns_tradable_o2o, close_df=close_df, open_df=open_df)

        # å®šä¹‰æµ‹è¯•é…ç½®
        test_configurations = {
            'o2o': o2o_calculator
        }
        returns_calculator_config = self.factor_manager.data_manager.config['evaluation']['returns_calculator']
        returns_calculator_result = {name: test_configurations[name] for name in returns_calculator_config}
        return factor_data_t1,is_composite_factor,start_date, end_date, stock_pool_index_code, stock_pool_name,  style_category_type, returns_calculator_result

    def test_factor_entity_service_for_composite_factor(self, factor_name, factor_data_shifted, stock_pool_index_name,test_configurations, start_date, end_date, stock_pool_index_code):
        all_configs_results = {}
        for calculator_name, func in test_configurations.items():
            processed_df, ic_s, ic_st, q_r,q_daily_returns_df_proc, q_st, turnover, fm_returns_series_dict, fm_t_stats_series_dict, fm_summary_dict, style_correlation_dict \
                = self.comprehensive_test(
                target_factor_name=factor_name,
                factor_data_shifted =factor_data_shifted ,
                stock_pool_index_name=stock_pool_index_name,
                returns_calculator=func,
                preprocess_method="standard",
                start_date=start_date,
                end_date=end_date,
                need_process_factor=False, #å› ä¸ºåˆæˆå¥½çš„å› å­æ— éœ€å†æ¬¡ä¸­æ€§åŒ–äº†ã€‚å®ƒçš„å­å¼Ÿå·²ç»ä½“éªŒè¿‡ä¸­æ€§åŒ–äº†
                do_ic_test=True, do_turnover_test=True, do_quantile_test=True, do_fama_test=True,
                do_style_correlation_test=True
            )
            single_config_results = {
                "processed_factor_df": processed_df,
                "ic_series_periods_dict_processed": ic_s,
                "ic_stats_periods_dict_processed": ic_st,
                "quantile_returns_series_periods_dict_processed": q_r,
                "q_daily_returns_df_processed": q_daily_returns_df_proc,
                "quantile_stats_periods_dict_processed": q_st,
                "fm_returns_series_periods_dict": fm_returns_series_dict,
                "fm_stat_results_periods_dict": fm_summary_dict,
                "turnover_stats_periods_dict": turnover,
                "style_correlation_dict": style_correlation_dict
            }
            # b) å°†æœ¬æ¬¡é…ç½®çš„æ‰€æœ‰ç»“æœæ‰“åŒ…
            self.factorResultsManager._save_factor_results(  # å‡è®¾ä¿å­˜å‡½æ•°åœ¨FactorManagerä¸­
                factor_name=factor_name,
                stock_index=stock_pool_index_code,
                start_date=start_date,
                end_date=end_date,
                returns_calculator_func_name=calculator_name,
                results=single_config_results
            )
            all_configs_results[calculator_name] = single_config_results
        return all_configs_results

    def test_factor_entity_service_by_smart_composite(self, factor_name, stock_pool_index_name,his_snap_config_id):
        factor_data_shifted, is_composite_factor, start_date, end_date, stock_pool_index_code, stock_pool_name, style_category, test_configurations \
            = self.prepare_date_for_entity_service(
            factor_name, stock_pool_index_name,his_snap_config_id)

        if not is_composite_factor:
            raise ValueError("åªæ”¯æŒåˆæˆå› å­çš„æµ‹è¯•")
        return self.test_factor_entity_service_for_composite_factor(factor_name, factor_data_shifted,
                                                                        stock_pool_name, test_configurations,
                                                                        start_date, end_date, stock_pool_index_code)